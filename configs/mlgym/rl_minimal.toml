# Minimal Test Config - No Docker, just tests the RL pipeline
#
# Run with:
#   cd air-agent && uv run rl @ configs/mlgym/rl_minimal.toml

# GPU allocation:
# - GPU 1: vLLM inference server
# - GPUs 2-7: FSDP trainer
inference_gpu_ids = [1]
trainer_gpu_ids = [2, 3, 4, 5, 6, 7]

max_steps = 3
seq_len = 4096

[ckpt]
interval = 5

[model]
name = "Qwen/Qwen3-4B-Instruct-2507"

[wandb]
project = "mlgym-rl-debug"
name = "minimal-test"

# ═══════════════════════════════════════════════════════════════
# TRAINER CONFIG
# ═══════════════════════════════════════════════════════════════
[trainer.model]
impl = "auto"

[trainer.model.ac]
freq = 1

[trainer.model.lora]
rank = 16
alpha = 32

[trainer.optim]
lr = 1e-5

# ═══════════════════════════════════════════════════════════════
# ORCHESTRATOR CONFIG
# ═══════════════════════════════════════════════════════════════
[orchestrator]
batch_size = 8
rollouts_per_example = 4
trajectory_strategy = "branching"

[orchestrator.log]
env_worker_logs = true
level = "DEBUG"

[orchestrator.sampling]
max_tokens = 256
temperature = 0.8

# Minimal test environment - no Docker
[[orchestrator.env]]
id = "air_mlgym_minimal"
name = "titanic"
args = { task_configs = ["titanic.yaml"], max_turns = 3, num_examples_per_task = 5 }

# ═══════════════════════════════════════════════════════════════
# INFERENCE CONFIG
# ═══════════════════════════════════════════════════════════════
[inference.model]
max_model_len = 4096
