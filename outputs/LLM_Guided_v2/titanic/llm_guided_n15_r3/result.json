{
  "task": "Titanic Survival Prediction",
  "primary_metric": "accuracy",
  "higher_is_better": true,
  "selection_strategy": "llm_guided",
  "best_node_id": "root_2",
  "best_score": 0.9330143540669856,
  "baseline_score": 0.76555,
  "improvement": 0.16746435406698568,
  "total_nodes": 16,
  "elapsed_seconds": 1468.5,
  "memory": [
    "LightGBM performs best when hyperparameters are carefully tuned and preprocessing avoids errors related to feature names and target encoding.",
    "LightGBM requires careful handling of feature names to avoid JSON character issues and performs best with precise hyperparameter tuning.",
    "LightGBM performs best when feature names and target encoding are handled carefully to avoid errors.",
    "LightGBM performs best when feature names are simple alphanumeric strings, avoiding JSON character issues.",
    "LightGBM performs best when feature names are simple alphanumeric strings, avoiding JSON character issues."
  ],
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 4,
      "score": 0.76555,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 0,
      "score": 0.8277511961722488,
      "strategy": "Use a Random Forest Classifier with n_estimators=100. For preprocessing, fill numeric NaN values wit"
    },
    "root_1": {
      "depth": 1,
      "num_children": 0,
      "score": null,
      "strategy": "Use XGBoost with the following settings: n_estimators=100, learning_rate=0.1, max_depth=3. For prepr"
    },
    "root_2": {
      "depth": 1,
      "num_children": 11,
      "score": 0.9330143540669856,
      "strategy": "Use LightGBM with the following settings: n_estimators=100, learning_rate=0.1, max_depth=3. For prep"
    },
    "root_3": {
      "depth": 1,
      "num_children": 0,
      "score": 0.8803827751196173,
      "strategy": "Use CatBoost with the following settings: iterations=500, learning_rate=0.03, depth=6. For preproces"
    },
    "root_2_0": {
      "depth": 2,
      "num_children": 0,
      "score": 0.861244019138756,
      "strategy": "Use LightGBM with the following settings: n_estimators=200, learning_rate=0.05, max_depth=4. For pre"
    },
    "root_2_1": {
      "depth": 2,
      "num_children": 0,
      "score": null,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.05`, `max_depth=4`, `"
    },
    "root_2_2": {
      "depth": 2,
      "num_children": 0,
      "score": null,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.05`, `max_depth=4`, `"
    },
    "root_2_3": {
      "depth": 2,
      "num_children": 0,
      "score": 0.8588516746411483,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.05`, `max_depth=4`, `"
    },
    "root_2_4": {
      "depth": 2,
      "num_children": 0,
      "score": 0.8732057416267942,
      "strategy": "Use LightGBM with the following settings: `n_estimators=100`, `learning_rate=0.1`, `max_depth=3`. Fo"
    },
    "root_2_5": {
      "depth": 2,
      "num_children": 0,
      "score": 0.868421052631579,
      "strategy": "Use LightGBM with the following settings: `n_estimators=100`, `learning_rate=0.1`, `max_depth=3`. Fo"
    },
    "root_2_6": {
      "depth": 2,
      "num_children": 0,
      "score": null,
      "strategy": "Use LightGBM with the following settings: `n_estimators=120`, `learning_rate=0.08`, `max_depth=3`, `"
    },
    "root_2_7": {
      "depth": 2,
      "num_children": 0,
      "score": 0.7727272727272727,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.07`, `max_depth=4`, `"
    },
    "root_2_8": {
      "depth": 2,
      "num_children": 0,
      "score": 0.7727272727272727,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.07`, `max_depth=4`, `"
    },
    "root_2_9": {
      "depth": 2,
      "num_children": 0,
      "score": 0.868421052631579,
      "strategy": "Use LightGBM with the following settings: `n_estimators=130`, `learning_rate=0.09`, `max_depth=3`, `"
    },
    "root_2_10": {
      "depth": 2,
      "num_children": 0,
      "score": 0.8732057416267942,
      "strategy": "Use LightGBM with the following settings: `n_estimators=100`, `learning_rate=0.1`, `max_depth=3`. Fo"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 0.76555,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2",
        "root_3"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Use a Random Forest Classifier with n_estimators=100. For preprocessing, fill numeric NaN values wit",
      "score": 0.8277511961722488,
      "actions_count": 10,
      "children": [],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Use XGBoost with the following settings: n_estimators=100, learning_rate=0.1, max_depth=3. For prepr",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Use LightGBM with the following settings: n_estimators=100, learning_rate=0.1, max_depth=3. For prep",
      "score": 0.9330143540669856,
      "actions_count": 12,
      "children": [
        "root_2_0",
        "root_2_1",
        "root_2_2",
        "root_2_3",
        "root_2_4",
        "root_2_5",
        "root_2_6",
        "root_2_7",
        "root_2_8",
        "root_2_9",
        "root_2_10"
      ],
      "error": null
    },
    "root_3": {
      "node_id": "root_3",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Use CatBoost with the following settings: iterations=500, learning_rate=0.03, depth=6. For preproces",
      "score": 0.8803827751196173,
      "actions_count": 3,
      "children": [],
      "error": null
    },
    "root_2_0": {
      "node_id": "root_2_0",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: n_estimators=200, learning_rate=0.05, max_depth=4. For pre",
      "score": 0.861244019138756,
      "actions_count": 7,
      "children": [],
      "error": null
    },
    "root_2_1": {
      "node_id": "root_2_1",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.05`, `max_depth=4`, `",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_2_2": {
      "node_id": "root_2_2",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.05`, `max_depth=4`, `",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_2_3": {
      "node_id": "root_2_3",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.05`, `max_depth=4`, `",
      "score": 0.8588516746411483,
      "actions_count": 5,
      "children": [],
      "error": null
    },
    "root_2_4": {
      "node_id": "root_2_4",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=100`, `learning_rate=0.1`, `max_depth=3`. Fo",
      "score": 0.8732057416267942,
      "actions_count": 3,
      "children": [],
      "error": null
    },
    "root_2_5": {
      "node_id": "root_2_5",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=100`, `learning_rate=0.1`, `max_depth=3`. Fo",
      "score": 0.868421052631579,
      "actions_count": 3,
      "children": [],
      "error": null
    },
    "root_2_6": {
      "node_id": "root_2_6",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=120`, `learning_rate=0.08`, `max_depth=3`, `",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_2_7": {
      "node_id": "root_2_7",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.07`, `max_depth=4`, `",
      "score": 0.7727272727272727,
      "actions_count": 9,
      "children": [],
      "error": null
    },
    "root_2_8": {
      "node_id": "root_2_8",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=150`, `learning_rate=0.07`, `max_depth=4`, `",
      "score": 0.7727272727272727,
      "actions_count": 3,
      "children": [],
      "error": null
    },
    "root_2_9": {
      "node_id": "root_2_9",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=130`, `learning_rate=0.09`, `max_depth=3`, `",
      "score": 0.868421052631579,
      "actions_count": 9,
      "children": [],
      "error": null
    },
    "root_2_10": {
      "node_id": "root_2_10",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Use LightGBM with the following settings: `n_estimators=100`, `learning_rate=0.1`, `max_depth=3`. Fo",
      "score": 0.8732057416267942,
      "actions_count": 11,
      "children": [],
      "error": null
    }
  }
}