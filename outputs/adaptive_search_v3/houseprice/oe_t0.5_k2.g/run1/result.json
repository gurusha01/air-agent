{
  "task": "House Price Prediction (Kaggle)",
  "primary_metric": "r2",
  "higher_is_better": true,
  "selection_strategy": "open-ended",
  "best_node_id": "root_0_0",
  "best_score": 0.9035687332706274,
  "baseline_score": 0.0,
  "improvement": 0.9035687332706274,
  "total_nodes": 13,
  "elapsed_seconds": 1062.6,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 3,
      "score": 0.0,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 2,
      "score": 0.8751655713764876,
      "strategy": "Apply polynomial feature expansion on key numerical variables (e.g., area, year_built) to capture no"
    },
    "root_1": {
      "depth": 1,
      "num_children": 2,
      "score": 0.7761547985957598,
      "strategy": "Apply polynomial feature expansion to the input variables (e.g., square, cube, or interaction terms "
    },
    "root_2": {
      "depth": 1,
      "num_children": 0,
      "score": null,
      "strategy": "Apply polynomial feature expansion to capture non-linear relationships in the data, using degree-2 o"
    },
    "root_0_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.9035687332706274,
      "strategy": "Replace the Ridge Regression model with a Gradient Boosting Machine (e.g., XGBoost or LightGBM) usin"
    },
    "root_0_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.8810325814616072,
      "strategy": "Apply a Random Forest ensemble with feature importance-based pruning to eliminate low-impact feature"
    },
    "root_1_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.8947461780903402,
      "strategy": "Replace the Ridge Regression model with a Gradient Boosting Machine (e.g., XGBoost or LightGBM) usin"
    },
    "root_1_0_0": {
      "depth": 3,
      "num_children": 0,
      "score": null,
      "strategy": "Apply target encoding to categorical variables (e.g., neighborhood, street type) using k-classes smo"
    },
    "root_0_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.7050995079094371,
      "strategy": "Apply a gradient boosting machine (e.g., XGBoost or LightGBM) with early stopping on validation data"
    },
    "root_0_1": {
      "depth": 2,
      "num_children": 1,
      "score": 0.8997766704626822,
      "strategy": "Replace the Ridge Regression model with a Gradient Boosting Machine (e.g., XGBoost or LightGBM) usin"
    },
    "root_0_1_0": {
      "depth": 3,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a deep neural network with a fully connected architecture (e.g., 3-5 hidden layers with 128 ne"
    },
    "root_0_0_0_0_0": {
      "depth": 5,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a deep feedforward network) using d"
    },
    "root_1_1": {
      "depth": 2,
      "num_children": 0,
      "score": -0.28027010494545146,
      "strategy": "Apply a Gaussian Process Regression model with a Mat\u00e9rn kernel to model the non-linear and smooth re"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 0.0,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply polynomial feature expansion on key numerical variables (e.g., area, year_built) to capture no",
      "score": 0.8751655713764876,
      "actions_count": 5,
      "children": [
        "root_0_0",
        "root_0_1"
      ],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply polynomial feature expansion to the input variables (e.g., square, cube, or interaction terms ",
      "score": 0.7761547985957598,
      "actions_count": 6,
      "children": [
        "root_1_0",
        "root_1_1"
      ],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply polynomial feature expansion to capture non-linear relationships in the data, using degree-2 o",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_0_0": {
      "node_id": "root_0_0",
      "parent_id": "root_0",
      "depth": 2,
      "strategy": "Replace the Ridge Regression model with a Gradient Boosting Machine (e.g., XGBoost or LightGBM) usin",
      "score": 0.9035687332706274,
      "actions_count": 3,
      "children": [
        "root_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0": {
      "node_id": "root_0_0_0",
      "parent_id": "root_0_0",
      "depth": 3,
      "strategy": "Apply a Random Forest ensemble with feature importance-based pruning to eliminate low-impact feature",
      "score": 0.8810325814616072,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0": {
      "node_id": "root_1_0",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "Replace the Ridge Regression model with a Gradient Boosting Machine (e.g., XGBoost or LightGBM) usin",
      "score": 0.8947461780903402,
      "actions_count": 3,
      "children": [
        "root_1_0_0"
      ],
      "error": null
    },
    "root_1_0_0": {
      "node_id": "root_1_0_0",
      "parent_id": "root_1_0",
      "depth": 3,
      "strategy": "Apply target encoding to categorical variables (e.g., neighborhood, street type) using k-classes smo",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_0_0_0_0": {
      "node_id": "root_0_0_0_0",
      "parent_id": "root_0_0_0",
      "depth": 4,
      "strategy": "Apply a gradient boosting machine (e.g., XGBoost or LightGBM) with early stopping on validation data",
      "score": 0.7050995079094371,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_1": {
      "node_id": "root_0_1",
      "parent_id": "root_0",
      "depth": 2,
      "strategy": "Replace the Ridge Regression model with a Gradient Boosting Machine (e.g., XGBoost or LightGBM) usin",
      "score": 0.8997766704626822,
      "actions_count": 3,
      "children": [
        "root_0_1_0"
      ],
      "error": null
    },
    "root_0_1_0": {
      "node_id": "root_0_1_0",
      "parent_id": "root_0_1",
      "depth": 3,
      "strategy": "Apply a deep neural network with a fully connected architecture (e.g., 3-5 hidden layers with 128 ne",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0",
      "parent_id": "root_0_0_0_0",
      "depth": 5,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a deep feedforward network) using d",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_1_1": {
      "node_id": "root_1_1",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "Apply a Gaussian Process Regression model with a Mat\u00e9rn kernel to model the non-linear and smooth re",
      "score": -0.28027010494545146,
      "actions_count": 3,
      "children": [],
      "error": null
    }
  }
}