{
  "task": "Titanic Survival Prediction",
  "primary_metric": "accuracy",
  "higher_is_better": true,
  "selection_strategy": "ucb",
  "best_node_id": "root_3_0_1_1_0_0_0_0",
  "best_score": 0.9736842105263158,
  "baseline_score": 0.76555,
  "improvement": 0.20813421052631587,
  "total_nodes": 61,
  "elapsed_seconds": 20435.1,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 4,
      "score": 0.76555,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a gradient boosting machine (e.g., XGBoost or LightGBM) with categorical feature binning and t"
    },
    "root_1": {
      "depth": 1,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with targeted feature interaction"
    },
    "root_2": {
      "depth": 1,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with target encoding for categorical fea"
    },
    "root_3": {
      "depth": 1,
      "num_children": 2,
      "score": 0.9473684210526315,
      "strategy": "Apply a simple feature engineering step by creating a new binary feature \"family_size_category\" that"
    },
    "root_3_0": {
      "depth": 2,
      "num_children": 2,
      "score": 0.8708133971291866,
      "strategy": "Create a gradient-boosted tree model (e.g., XGBoost or LightGBM) using only the categorical features"
    },
    "root_3_0_0": {
      "depth": 3,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a deep neural network (DNN) model with a multi-layer perceptron architecture to capture co"
    },
    "root_3_1": {
      "depth": 2,
      "num_children": 1,
      "score": 0.7966507177033493,
      "strategy": "Create a gradient-boosted tree model (e.g., XGBoost or LightGBM) using the original features, with a"
    },
    "root_3_1_0": {
      "depth": 3,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a neural network with an ensemble of dense layers to model high-dimensional non-linear int"
    },
    "root_3_0_1": {
      "depth": 3,
      "num_children": 2,
      "score": 0.9688995215311005,
      "strategy": "Introduce a deep neural network (DNN) model with a multi-layered architecture to capture high-dimens"
    },
    "root_3_0_1_0": {
      "depth": 4,
      "num_children": 2,
      "score": 0.868421052631579,
      "strategy": "Introduce a gradient boosting model (e.g., XGBoost or LightGBM) with tree ensembling to capture non-"
    },
    "root_3_0_1_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 0.868421052631579,
      "strategy": "Introduce a neural network with an embedding layer for categorical variables (e.g., passenger class,"
    },
    "root_3_0_1_0_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.80622009569378,
      "strategy": "Apply gradient boosting with tree-based models (e.g., LightGBM or XGBoost) using target-aware splits"
    },
    "root_3_0_1_0_0_0_0": {
      "depth": 7,
      "num_children": 1,
      "score": 0.8588516746411483,
      "strategy": "Introduce a random forest ensemble with bootstrap aggregating (bagging) and apply target-specific fe"
    },
    "root_3_0_1_0_0_0_0_0": {
      "depth": 8,
      "num_children": 1,
      "score": 0.6124401913875598,
      "strategy": "Replace the random forest with a gradient boosting machine (e.g., XGBoost or LightGBM) using a learn"
    },
    "root_3_0_1_0_0_0_0_0_0": {
      "depth": 9,
      "num_children": 2,
      "score": 0.8636363636363636,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a multilayer perceptron) and use an"
    },
    "root_3_0_1_0_0_0_0_0_0_0": {
      "depth": 10,
      "num_children": 2,
      "score": 0.8803827751196173,
      "strategy": "Replace the neural network with a random forest ensemble with 100 trees, using bootstrap aggregating"
    },
    "root_3_0_1_0_0_0_0_0_0_0_0": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the random forest with a gradient boosting machine (e.g., XGBoost or LightGBM) using early s"
    },
    "root_3_0_1_0_0_0_0_0_0_1": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the neural network with a random forest ensemble using 100 trees, with feature bagging and o"
    },
    "root_3_0_1_0_0_0_0_0_0_0_1": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the random forest with a gradient boosting machine (e.g., XGBoost or LightGBM) using early s"
    },
    "root_3_0_1_1": {
      "depth": 4,
      "num_children": 1,
      "score": 0.8588516746411483,
      "strategy": "Replace the deep neural network with a gradient boosting ensemble (e.g., XGBoost or LightGBM) using "
    },
    "root_3_0_1_1_0": {
      "depth": 5,
      "num_children": 1,
      "score": 0.6220095693779905,
      "strategy": "Introduce a random forest with permutation-based feature importance pruning to identify and retain o"
    },
    "root_3_0_1_1_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.6555023923444976,
      "strategy": "Replace the ensemble of shallow trees with a deep neural network (DNN) using a feedforward architect"
    },
    "root_3_0_1_1_0_0_0": {
      "depth": 7,
      "num_children": 2,
      "score": 0.868421052631579,
      "strategy": "Replace the deep neural network with a gradient boosting ensemble (e.g., LightGBM or XGBoost) using "
    },
    "root_3_0_1_1_0_0_0_0": {
      "depth": 8,
      "num_children": 2,
      "score": 0.9736842105263158,
      "strategy": "Introduce a graph neural network (GNN) model that treats passengers as nodes in a social network, wi"
    },
    "root_3_0_1_1_0_0_0_0_0": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a temporal graph network (TGN) that models the Titanic voyage as a dynamic event, where pa"
    },
    "root_3_0_1_1_0_0_0_1": {
      "depth": 8,
      "num_children": 2,
      "score": 0.9712918660287081,
      "strategy": "Apply a recurrent neural network (RNN) with an LSTM layer to model temporal dependencies in passenge"
    },
    "root_3_0_1_1_0_0_0_1_0": {
      "depth": 9,
      "num_children": 2,
      "score": 0.9641148325358851,
      "strategy": "Replace the LSTM-based RNN with a graph neural network (GNN) that models passengers as nodes in a so"
    },
    "root_3_0_1_1_0_0_0_1_0_0": {
      "depth": 10,
      "num_children": 2,
      "score": 0.9712918660287081,
      "strategy": "Introduce a transformer-based model that treats the passenger data as a sequence of structured inter"
    },
    "root_3_0_1_1_0_0_0_1_0_0_0": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a random forest ensemble where each tree is trained on a different subsampled subset of th"
    },
    "root_3_0_1_1_0_0_0_0_1": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a transformer-based model that processes passenger records as sequences, where each passen"
    },
    "root_3_0_1_1_0_0_0_1_0_1": {
      "depth": 10,
      "num_children": 2,
      "score": 0.9688995215311005,
      "strategy": "Introduce a transformer-based model that treats each passenger as a sequence of contextual features "
    },
    "root_3_0_1_1_0_0_0_1_0_1_0": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) with heterogeneous edge types, where nodes represent passenge"
    },
    "root_3_0_1_1_0_0_0_1_0_0_1": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with custom feature engineeri"
    },
    "root_3_0_1_1_0_0_0_1_0_1_1": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a Bayesian Neural Network (BNN) with hierarchical priors over passenger features (e.g., ag"
    },
    "root_3_0_1_1_0_0_0_1_1": {
      "depth": 9,
      "num_children": 2,
      "score": 0.9641148325358851,
      "strategy": "Replace the RNN-LSTM approach with a graph neural network (GNN) that models passengers as nodes in a"
    },
    "root_3_0_1_1_0_0_0_1_1_0": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a transformer-based model with attention mechanisms that explicitly model passenger co-occ"
    },
    "root_3_0_1_1_0_0_0_1_1_1": {
      "depth": 10,
      "num_children": 2,
      "score": 0.9688995215311005,
      "strategy": "Introduce a transformer-based model with self-attention mechanisms applied directly to the passenger"
    },
    "root_3_0_1_1_0_0_0_1_1_1_0": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a graph neural network (GNN) with node embeddings to model passenger relationships explicitly."
    },
    "root_3_0_1_1_0_0_0_1_1_1_1": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the transformer-based sequence model with a gradient-boosted tree ensemble (e.g., XGBoost or"
    },
    "root_3_0_1_0_1": {
      "depth": 5,
      "num_children": 2,
      "score": 0.9497607655502392,
      "strategy": "Introduce a neural network with an embedding layer for categorical variables (e.g., passenger class,"
    },
    "root_3_0_1_0_1_0": {
      "depth": 6,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the neural network with a Gradient Boosting Machine (e.g., LightGBM or XGBoost) using target"
    },
    "root_3_0_1_0_1_1": {
      "depth": 6,
      "num_children": 1,
      "score": 0.8899521531100478,
      "strategy": "Replace the neural network with a Gradient Boosting Machine (e.g., LightGBM or XGBoost) using target"
    },
    "root_3_0_1_0_1_1_0": {
      "depth": 7,
      "num_children": 2,
      "score": 0.9641148325358851,
      "strategy": "Apply a deep autoencoder-based feature learning approach where passenger data is first encoded into "
    },
    "root_3_0_1_0_1_1_0_0": {
      "depth": 8,
      "num_children": 2,
      "score": 0.9688995215311005,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships based on social connections "
    },
    "root_3_0_1_0_1_1_0_0_0": {
      "depth": 9,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a temporal graph convolutional network (TGCN) that models time-dependent passenger interac"
    },
    "root_3_0_1_0_1_1_0_0_0_0": {
      "depth": 10,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a survival prediction model based on graph attention networks (GATs) with dynamic node fea"
    },
    "root_3_0_1_0_1_1_0_0_0_0_0": {
      "depth": 11,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a survival prediction model based on transformer-based temporal modeling with latent state"
    },
    "root_3_0_1_0_1_1_0_0_0_0_0_0": {
      "depth": 12,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a survival prediction model based on graph neural networks (GNNs) that explicitly model pa"
    },
    "root_3_0_1_0_1_1_0_0_0_0_0_0_0": {
      "depth": 13,
      "num_children": 1,
      "score": 0.7894736842105263,
      "strategy": "Introduce a survival prediction model based on gradient-boosted trees (e.g., XGBoost or LightGBM) us"
    },
    "root_3_0_1_0_1_1_0_0_0_0_0_0_0_0": {
      "depth": 14,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a survival prediction model based on a recurrent neural network (RNN) with LSTM layers to "
    },
    "root_3_0_1_0_1_1_0_1": {
      "depth": 8,
      "num_children": 1,
      "score": 0.8732057416267942,
      "strategy": "Replace the deep autoencoder with a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) that "
    },
    "root_3_0_1_0_1_1_0_1_0": {
      "depth": 9,
      "num_children": 1,
      "score": 0.8971291866028708,
      "strategy": "Apply a stacked ensemble of three models: first, use a neural network with a small number of hidden "
    },
    "root_3_0_1_0_1_1_0_1_0_0": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the neural network with a gradient boosting machine (e.g., XGBoost or LightGBM) as the first"
    },
    "root_3_0_1_0_1_1_0_0_1": {
      "depth": 9,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a temporal graph convolutional network (TGCN) that models the Titanic voyage as a time-ser"
    },
    "root_3_0_1_0_1_1_0_0_1_0": {
      "depth": 10,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a survival prediction model based on physics-informed neural networks (PINNs) that simulat"
    },
    "root_3_0_1_0_1_1_0_0_1_0_0": {
      "depth": 11,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a survival prediction model based on time-series forecasting using Long Short-Term Memory "
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0": {
      "depth": 12,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a graph-based survival prediction model using Graph Neural Networks (GNNs) to represent pa"
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0_0": {
      "depth": 13,
      "num_children": 1,
      "score": 0.9688995215311005,
      "strategy": "Introduce a transformer-based survival model that treats passenger records as sequential text tokens"
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0": {
      "depth": 14,
      "num_children": 1,
      "score": 0.8492822966507177,
      "strategy": "Introduce a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with custom feature interacti"
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0_0": {
      "depth": 15,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a deep autoencoder-based feature reconstruction approach to learn latent representations o"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 0.76555,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2",
        "root_3"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting machine (e.g., XGBoost or LightGBM) with categorical feature binning and t",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with targeted feature interaction",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with target encoding for categorical fea",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_3": {
      "node_id": "root_3",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a simple feature engineering step by creating a new binary feature \"family_size_category\" that",
      "score": 0.9473684210526315,
      "actions_count": 3,
      "children": [
        "root_3_0",
        "root_3_1"
      ],
      "error": null
    },
    "root_3_0": {
      "node_id": "root_3_0",
      "parent_id": "root_3",
      "depth": 2,
      "strategy": "Create a gradient-boosted tree model (e.g., XGBoost or LightGBM) using only the categorical features",
      "score": 0.8708133971291866,
      "actions_count": 3,
      "children": [
        "root_3_0_0",
        "root_3_0_1"
      ],
      "error": null
    },
    "root_3_0_0": {
      "node_id": "root_3_0_0",
      "parent_id": "root_3_0",
      "depth": 3,
      "strategy": "Introduce a deep neural network (DNN) model with a multi-layer perceptron architecture to capture co",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_3_1": {
      "node_id": "root_3_1",
      "parent_id": "root_3",
      "depth": 2,
      "strategy": "Create a gradient-boosted tree model (e.g., XGBoost or LightGBM) using the original features, with a",
      "score": 0.7966507177033493,
      "actions_count": 5,
      "children": [
        "root_3_1_0"
      ],
      "error": null
    },
    "root_3_1_0": {
      "node_id": "root_3_1_0",
      "parent_id": "root_3_1",
      "depth": 3,
      "strategy": "Introduce a neural network with an ensemble of dense layers to model high-dimensional non-linear int",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_3_0_1": {
      "node_id": "root_3_0_1",
      "parent_id": "root_3_0",
      "depth": 3,
      "strategy": "Introduce a deep neural network (DNN) model with a multi-layered architecture to capture high-dimens",
      "score": 0.9688995215311005,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0",
        "root_3_0_1_1"
      ],
      "error": null
    },
    "root_3_0_1_0": {
      "node_id": "root_3_0_1_0",
      "parent_id": "root_3_0_1",
      "depth": 4,
      "strategy": "Introduce a gradient boosting model (e.g., XGBoost or LightGBM) with tree ensembling to capture non-",
      "score": 0.868421052631579,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_0",
        "root_3_0_1_0_1"
      ],
      "error": null
    },
    "root_3_0_1_0_0": {
      "node_id": "root_3_0_1_0_0",
      "parent_id": "root_3_0_1_0",
      "depth": 5,
      "strategy": "Introduce a neural network with an embedding layer for categorical variables (e.g., passenger class,",
      "score": 0.868421052631579,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_0_0": {
      "node_id": "root_3_0_1_0_0_0",
      "parent_id": "root_3_0_1_0_0",
      "depth": 6,
      "strategy": "Apply gradient boosting with tree-based models (e.g., LightGBM or XGBoost) using target-aware splits",
      "score": 0.80622009569378,
      "actions_count": 4,
      "children": [
        "root_3_0_1_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_0_0_0": {
      "node_id": "root_3_0_1_0_0_0_0",
      "parent_id": "root_3_0_1_0_0_0",
      "depth": 7,
      "strategy": "Introduce a random forest ensemble with bootstrap aggregating (bagging) and apply target-specific fe",
      "score": 0.8588516746411483,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_0_0_0",
      "depth": 8,
      "strategy": "Replace the random forest with a gradient boosting machine (e.g., XGBoost or LightGBM) using a learn",
      "score": 0.6124401913875598,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_0_0_0_0",
      "depth": 9,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a multilayer perceptron) and use an",
      "score": 0.8636363636363636,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_0_0_0_0_0_0",
        "root_3_0_1_0_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_3_0_1_0_0_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_0_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_0_0_0_0_0",
      "depth": 10,
      "strategy": "Replace the neural network with a random forest ensemble with 100 trees, using bootstrap aggregating",
      "score": 0.8803827751196173,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_0_0_0_0_0_0_0",
        "root_3_0_1_0_0_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_3_0_1_0_0_0_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_0_0_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_0_0_0_0_0_0",
      "depth": 11,
      "strategy": "Replace the random forest with a gradient boosting machine (e.g., XGBoost or LightGBM) using early s",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29336 input tokens (4096 > 32768 - 29336). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_0_0_0_0_0_0_1": {
      "node_id": "root_3_0_1_0_0_0_0_0_0_1",
      "parent_id": "root_3_0_1_0_0_0_0_0_0",
      "depth": 10,
      "strategy": "Replace the neural network with a random forest ensemble using 100 trees, with feature bagging and o",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28726 input tokens (4096 > 32768 - 28726). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_0_0_0_0_0_0_0_1": {
      "node_id": "root_3_0_1_0_0_0_0_0_0_0_1",
      "parent_id": "root_3_0_1_0_0_0_0_0_0_0",
      "depth": 11,
      "strategy": "Replace the random forest with a gradient boosting machine (e.g., XGBoost or LightGBM) using early s",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29379 input tokens (4096 > 32768 - 29379). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1": {
      "node_id": "root_3_0_1_1",
      "parent_id": "root_3_0_1",
      "depth": 4,
      "strategy": "Replace the deep neural network with a gradient boosting ensemble (e.g., XGBoost or LightGBM) using ",
      "score": 0.8588516746411483,
      "actions_count": 7,
      "children": [
        "root_3_0_1_1_0"
      ],
      "error": null
    },
    "root_3_0_1_1_0": {
      "node_id": "root_3_0_1_1_0",
      "parent_id": "root_3_0_1_1",
      "depth": 5,
      "strategy": "Introduce a random forest with permutation-based feature importance pruning to identify and retain o",
      "score": 0.6220095693779905,
      "actions_count": 11,
      "children": [
        "root_3_0_1_1_0_0"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0": {
      "node_id": "root_3_0_1_1_0_0",
      "parent_id": "root_3_0_1_1_0",
      "depth": 6,
      "strategy": "Replace the ensemble of shallow trees with a deep neural network (DNN) using a feedforward architect",
      "score": 0.6555023923444976,
      "actions_count": 11,
      "children": [
        "root_3_0_1_1_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0": {
      "node_id": "root_3_0_1_1_0_0_0",
      "parent_id": "root_3_0_1_1_0_0",
      "depth": 7,
      "strategy": "Replace the deep neural network with a gradient boosting ensemble (e.g., LightGBM or XGBoost) using ",
      "score": 0.868421052631579,
      "actions_count": 5,
      "children": [
        "root_3_0_1_1_0_0_0_0",
        "root_3_0_1_1_0_0_0_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_0": {
      "node_id": "root_3_0_1_1_0_0_0_0",
      "parent_id": "root_3_0_1_1_0_0_0",
      "depth": 8,
      "strategy": "Introduce a graph neural network (GNN) model that treats passengers as nodes in a social network, wi",
      "score": 0.9736842105263158,
      "actions_count": 5,
      "children": [
        "root_3_0_1_1_0_0_0_0_0",
        "root_3_0_1_1_0_0_0_0_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_0_0": {
      "node_id": "root_3_0_1_1_0_0_0_0_0",
      "parent_id": "root_3_0_1_1_0_0_0_0",
      "depth": 9,
      "strategy": "Introduce a temporal graph network (TGN) that models the Titanic voyage as a dynamic event, where pa",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28930 input tokens (4096 > 32768 - 28930). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_1": {
      "node_id": "root_3_0_1_1_0_0_0_1",
      "parent_id": "root_3_0_1_1_0_0_0",
      "depth": 8,
      "strategy": "Apply a recurrent neural network (RNN) with an LSTM layer to model temporal dependencies in passenge",
      "score": 0.9712918660287081,
      "actions_count": 5,
      "children": [
        "root_3_0_1_1_0_0_0_1_0",
        "root_3_0_1_1_0_0_0_1_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_1_0": {
      "node_id": "root_3_0_1_1_0_0_0_1_0",
      "parent_id": "root_3_0_1_1_0_0_0_1",
      "depth": 9,
      "strategy": "Replace the LSTM-based RNN with a graph neural network (GNN) that models passengers as nodes in a so",
      "score": 0.9641148325358851,
      "actions_count": 3,
      "children": [
        "root_3_0_1_1_0_0_0_1_0_0",
        "root_3_0_1_1_0_0_0_1_0_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_1_0_0": {
      "node_id": "root_3_0_1_1_0_0_0_1_0_0",
      "parent_id": "root_3_0_1_1_0_0_0_1_0",
      "depth": 10,
      "strategy": "Introduce a transformer-based model that treats the passenger data as a sequence of structured inter",
      "score": 0.9712918660287081,
      "actions_count": 3,
      "children": [
        "root_3_0_1_1_0_0_0_1_0_0_0",
        "root_3_0_1_1_0_0_0_1_0_0_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_1_0_0_0": {
      "node_id": "root_3_0_1_1_0_0_0_1_0_0_0",
      "parent_id": "root_3_0_1_1_0_0_0_1_0_0",
      "depth": 11,
      "strategy": "Introduce a random forest ensemble where each tree is trained on a different subsampled subset of th",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28774 input tokens (4096 > 32768 - 28774). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_0_1": {
      "node_id": "root_3_0_1_1_0_0_0_0_1",
      "parent_id": "root_3_0_1_1_0_0_0_0",
      "depth": 9,
      "strategy": "Introduce a transformer-based model that processes passenger records as sequences, where each passen",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28818 input tokens (4096 > 32768 - 28818). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_1_0_1": {
      "node_id": "root_3_0_1_1_0_0_0_1_0_1",
      "parent_id": "root_3_0_1_1_0_0_0_1_0",
      "depth": 10,
      "strategy": "Introduce a transformer-based model that treats each passenger as a sequence of contextual features ",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_1_0_0_0_1_0_1_0",
        "root_3_0_1_1_0_0_0_1_0_1_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_1_0_1_0": {
      "node_id": "root_3_0_1_1_0_0_0_1_0_1_0",
      "parent_id": "root_3_0_1_1_0_0_0_1_0_1",
      "depth": 11,
      "strategy": "Introduce a graph neural network (GNN) with heterogeneous edge types, where nodes represent passenge",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28834 input tokens (4096 > 32768 - 28834). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_1_0_0_1": {
      "node_id": "root_3_0_1_1_0_0_0_1_0_0_1",
      "parent_id": "root_3_0_1_1_0_0_0_1_0_0",
      "depth": 11,
      "strategy": "Introduce a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with custom feature engineeri",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28841 input tokens (4096 > 32768 - 28841). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_1_0_1_1": {
      "node_id": "root_3_0_1_1_0_0_0_1_0_1_1",
      "parent_id": "root_3_0_1_1_0_0_0_1_0_1",
      "depth": 11,
      "strategy": "Introduce a Bayesian Neural Network (BNN) with hierarchical priors over passenger features (e.g., ag",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28893 input tokens (4096 > 32768 - 28893). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_1_1": {
      "node_id": "root_3_0_1_1_0_0_0_1_1",
      "parent_id": "root_3_0_1_1_0_0_0_1",
      "depth": 9,
      "strategy": "Replace the RNN-LSTM approach with a graph neural network (GNN) that models passengers as nodes in a",
      "score": 0.9641148325358851,
      "actions_count": 3,
      "children": [
        "root_3_0_1_1_0_0_0_1_1_0",
        "root_3_0_1_1_0_0_0_1_1_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_1_1_0": {
      "node_id": "root_3_0_1_1_0_0_0_1_1_0",
      "parent_id": "root_3_0_1_1_0_0_0_1_1",
      "depth": 10,
      "strategy": "Introduce a transformer-based model with attention mechanisms that explicitly model passenger co-occ",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29012 input tokens (4096 > 32768 - 29012). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_1_1_1": {
      "node_id": "root_3_0_1_1_0_0_0_1_1_1",
      "parent_id": "root_3_0_1_1_0_0_0_1_1",
      "depth": 10,
      "strategy": "Introduce a transformer-based model with self-attention mechanisms applied directly to the passenger",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_1_0_0_0_1_1_1_0",
        "root_3_0_1_1_0_0_0_1_1_1_1"
      ],
      "error": null
    },
    "root_3_0_1_1_0_0_0_1_1_1_0": {
      "node_id": "root_3_0_1_1_0_0_0_1_1_1_0",
      "parent_id": "root_3_0_1_1_0_0_0_1_1_1",
      "depth": 11,
      "strategy": "Apply a graph neural network (GNN) with node embeddings to model passenger relationships explicitly.",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29087 input tokens (4096 > 32768 - 29087). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_1_0_0_0_1_1_1_1": {
      "node_id": "root_3_0_1_1_0_0_0_1_1_1_1",
      "parent_id": "root_3_0_1_1_0_0_0_1_1_1",
      "depth": 11,
      "strategy": "Replace the transformer-based sequence model with a gradient-boosted tree ensemble (e.g., XGBoost or",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29145 input tokens (4096 > 32768 - 29145). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_0_1": {
      "node_id": "root_3_0_1_0_1",
      "parent_id": "root_3_0_1_0",
      "depth": 5,
      "strategy": "Introduce a neural network with an embedding layer for categorical variables (e.g., passenger class,",
      "score": 0.9497607655502392,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_1_0",
        "root_3_0_1_0_1_1"
      ],
      "error": null
    },
    "root_3_0_1_0_1_0": {
      "node_id": "root_3_0_1_0_1_0",
      "parent_id": "root_3_0_1_0_1",
      "depth": 6,
      "strategy": "Replace the neural network with a Gradient Boosting Machine (e.g., LightGBM or XGBoost) using target",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_3_0_1_0_1_1": {
      "node_id": "root_3_0_1_0_1_1",
      "parent_id": "root_3_0_1_0_1",
      "depth": 6,
      "strategy": "Replace the neural network with a Gradient Boosting Machine (e.g., LightGBM or XGBoost) using target",
      "score": 0.8899521531100478,
      "actions_count": 9,
      "children": [
        "root_3_0_1_0_1_1_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0": {
      "node_id": "root_3_0_1_0_1_1_0",
      "parent_id": "root_3_0_1_0_1_1",
      "depth": 7,
      "strategy": "Apply a deep autoencoder-based feature learning approach where passenger data is first encoded into ",
      "score": 0.9641148325358851,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_1_1_0_0",
        "root_3_0_1_0_1_1_0_1"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0",
      "parent_id": "root_3_0_1_0_1_1_0",
      "depth": 8,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships based on social connections ",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_0",
        "root_3_0_1_0_1_1_0_0_1"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0",
      "depth": 9,
      "strategy": "Introduce a temporal graph convolutional network (TGCN) that models time-dependent passenger interac",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_0",
      "depth": 10,
      "strategy": "Introduce a survival prediction model based on graph attention networks (GATs) with dynamic node fea",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_0_0",
      "depth": 11,
      "strategy": "Introduce a survival prediction model based on transformer-based temporal modeling with latent state",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_0_0_0",
      "depth": 12,
      "strategy": "Introduce a survival prediction model based on graph neural networks (GNNs) that explicitly model pa",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_0_0_0_0",
      "depth": 13,
      "strategy": "Introduce a survival prediction model based on gradient-boosted trees (e.g., XGBoost or LightGBM) us",
      "score": 0.7894736842105263,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_1_1_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_0_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_0_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_0_0_0_0_0",
      "depth": 14,
      "strategy": "Introduce a survival prediction model based on a recurrent neural network (RNN) with LSTM layers to ",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28905 input tokens (4096 > 32768 - 28905). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_0_1_1_0_1": {
      "node_id": "root_3_0_1_0_1_1_0_1",
      "parent_id": "root_3_0_1_0_1_1_0",
      "depth": 8,
      "strategy": "Replace the deep autoencoder with a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) that ",
      "score": 0.8732057416267942,
      "actions_count": 5,
      "children": [
        "root_3_0_1_0_1_1_0_1_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_1_0": {
      "node_id": "root_3_0_1_0_1_1_0_1_0",
      "parent_id": "root_3_0_1_0_1_1_0_1",
      "depth": 9,
      "strategy": "Apply a stacked ensemble of three models: first, use a neural network with a small number of hidden ",
      "score": 0.8971291866028708,
      "actions_count": 8,
      "children": [
        "root_3_0_1_0_1_1_0_1_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_1_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_1_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_1_0",
      "depth": 10,
      "strategy": "Replace the neural network with a gradient boosting machine (e.g., XGBoost or LightGBM) as the first",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29342 input tokens (4096 > 32768 - 29342). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_3_0_1_0_1_1_0_0_1": {
      "node_id": "root_3_0_1_0_1_1_0_0_1",
      "parent_id": "root_3_0_1_0_1_1_0_0",
      "depth": 9,
      "strategy": "Introduce a temporal graph convolutional network (TGCN) that models the Titanic voyage as a time-ser",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_1_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_1_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_1_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_1",
      "depth": 10,
      "strategy": "Introduce a survival prediction model based on physics-informed neural networks (PINNs) that simulat",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_1_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_1_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_1_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_1_0",
      "depth": 11,
      "strategy": "Introduce a survival prediction model based on time-series forecasting using Long Short-Term Memory ",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_1_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_1_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_1_0_0",
      "depth": 12,
      "strategy": "Introduce a graph-based survival prediction model using Graph Neural Networks (GNNs) to represent pa",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_1_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_1_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_1_0_0_0",
      "depth": 13,
      "strategy": "Introduce a transformer-based survival model that treats passenger records as sequential text tokens",
      "score": 0.9688995215311005,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_1_0_0_0_0",
      "depth": 14,
      "strategy": "Introduce a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with custom feature interacti",
      "score": 0.8492822966507177,
      "actions_count": 3,
      "children": [
        "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0_0": {
      "node_id": "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0_0",
      "parent_id": "root_3_0_1_0_1_1_0_0_1_0_0_0_0_0",
      "depth": 15,
      "strategy": "Introduce a deep autoencoder-based feature reconstruction approach to learn latent representations o",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28806 input tokens (4096 > 32768 - 28806). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    }
  }
}