{
  "task": "Titanic Survival Prediction",
  "primary_metric": "accuracy",
  "higher_is_better": true,
  "selection_strategy": "open-ended",
  "best_node_id": "root_1_0_0_1",
  "best_score": 0.937799043062201,
  "baseline_score": 0.76555,
  "improvement": 0.172249043062201,
  "total_nodes": 61,
  "elapsed_seconds": 9298.5,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 5,
      "score": 0.76555,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 2,
      "score": 0.84688995215311,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with targeted feature interactions, such"
    },
    "root_1": {
      "depth": 1,
      "num_children": 1,
      "score": 0.8492822966507177,
      "strategy": "Apply a gradient boosting ensemble (e.g., XGBoost or LightGBM) with targeted categorical encoding (e"
    },
    "root_2": {
      "depth": 1,
      "num_children": 1,
      "score": 0.8755980861244019,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with targeted feature interactions, such"
    },
    "root_3": {
      "depth": 1,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a gradient-boosted tree model (e.g., XGBoost or LightGBM) with targeted feature interactions, "
    },
    "root_4": {
      "depth": 1,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with target encoding for categorical fea"
    },
    "root_2_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.361244019138756,
      "strategy": "Replace the gradient boosting model with a deep neural network (DNN) architecture, incorporating mul"
    },
    "root_1_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.7894736842105263,
      "strategy": "Replace the gradient boosting model with a deep neural network (DNN) architecture using a feedforwar"
    },
    "root_0_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.8421052631578947,
      "strategy": "Replace the gradient boosting model with a neural network architecture (e.g., a multi-layer perceptr"
    },
    "root_0_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.8229665071770335,
      "strategy": "Replace the neural network with a random forest ensemble that incorporates target encoding of catego"
    },
    "root_0_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.8349282296650717,
      "strategy": "Introduce a gradient-boosted tree model (e.g., XGBoost or LightGBM) with recursive feature eliminati"
    },
    "root_0_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 0.8277511961722488,
      "strategy": "Introduce a neural network with a deep architecture (e.g., multi-layer perceptron) and apply batch n"
    },
    "root_0_0_0_0_0_0": {
      "depth": 6,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) that models passenger relationships as a graph, where nodes r"
    },
    "root_1_0_0": {
      "depth": 3,
      "num_children": 2,
      "score": 0.8421052631578947,
      "strategy": "Replace the deep neural network with a random forest ensemble model, incorporating gradient boosting"
    },
    "root_1_0_0_0": {
      "depth": 4,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a Transformer-based model with attention mechanisms to capture complex, long-range depende"
    },
    "root_1_0_0_0_0": {
      "depth": 5,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a Graph Neural Network (GNN) to model passenger relationships as a graph, where nodes repr"
    },
    "root_1_0_0_0_0_0": {
      "depth": 6,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a Recurrent Neural Network (RNN) with a custom memory cell designed to encode temporal dep"
    },
    "root_1_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 2,
      "score": 0.8636363636363636,
      "strategy": "Introduce a LightGBM model trained on engineered features that capture socio-economic gradients (e.g"
    },
    "root_1_0_0_0_0_0_0_0": {
      "depth": 8,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a neural network with an embedding layer for categorical variables (e.g., passenger class,"
    },
    "root_2_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.8349282296650717,
      "strategy": "Replace the neural network with a random forest ensemble with 100 trees, using permutation feature i"
    },
    "root_2_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.6363636363636364,
      "strategy": "Replace the random forest with a gradient boosting model (e.g., XGBoost or LightGBM) and incorporate"
    },
    "root_2_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 0.6578947368421053,
      "strategy": "Replace the neural network with a support vector machine (SVM) using a radial basis function (RBF) k"
    },
    "root_2_0_0_0_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.6363636363636364,
      "strategy": "Replace the SVM with a gradient boosting machine (e.g., XGBoost or LightGBM) and incorporate tree-ba"
    },
    "root_2_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a deep neural network (DNN) with multiple hidden layers and non-linear activation functions (e"
    },
    "root_0_1": {
      "depth": 2,
      "num_children": 0,
      "score": null,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a deep feedforward network) and inc"
    },
    "root_1_0_0_0_0_0_0_1": {
      "depth": 8,
      "num_children": 2,
      "score": 0.8995215311004785,
      "strategy": "Introduce a Random Forest model trained on time-series features derived from passenger boarding sequ"
    },
    "root_1_0_0_0_0_0_0_1_0": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a Graph Neural Network (GNN) model where passengers are represented as nodes in a social i"
    },
    "root_1_0_0_0_0_0_0_1_1": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a Graph Neural Network (GNN) model that treats each passenger as a node in a social intera"
    },
    "root_1_0_0_0_0_0_1": {
      "depth": 7,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a Graph Autoencoder (GAE) with latent space clustering to model passenger relationships ba"
    },
    "root_1_0_0_0_0_0_1_0": {
      "depth": 8,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a Temporal Graph Neural Network (TGNN) that models passenger interactions over time (e.g.,"
    },
    "root_1_0_0_0_0_0_1_0_0": {
      "depth": 9,
      "num_children": 1,
      "score": 0.8444976076555024,
      "strategy": "Introduce a physics-informed neural network (PINN) that models the ship's structural dynamics and en"
    },
    "root_1_0_0_0_0_0_1_0_0_0": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) that models passengers as nodes in a social network, where ed"
    },
    "root_1_0_0_1": {
      "depth": 4,
      "num_children": 1,
      "score": 0.937799043062201,
      "strategy": "Introduce a transformer-based model with attention mechanisms to capture long-range dependencies in "
    },
    "root_1_0_0_1_0": {
      "depth": 5,
      "num_children": 1,
      "score": 0.6363636363636364,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships as a social network, where n"
    },
    "root_1_0_0_1_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.6363636363636364,
      "strategy": "Introduce a spatial-temporal transformer model that treats the ship's deck layout and cabin location"
    },
    "root_1_0_0_1_0_0_0": {
      "depth": 7,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) that models passenger survival based on social network struct"
    },
    "root_1_0_0_0_1": {
      "depth": 5,
      "num_children": 1,
      "score": 0.8373205741626795,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships as a social network, where e"
    },
    "root_1_0_0_0_1_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.8373205741626795,
      "strategy": "Introduce a transformer-based model with a tabular input encoder that treats passenger features as a"
    },
    "root_1_0_0_0_1_0_0": {
      "depth": 7,
      "num_children": 2,
      "score": 0.8373205741626795,
      "strategy": "Replace the transformer-based tabular encoder with a Bayesian Neural Network (BNN) that incorporates"
    },
    "root_1_0_0_0_1_0_0_0": {
      "depth": 8,
      "num_children": 1,
      "score": 0.8516746411483254,
      "strategy": "Apply a gradient-boosted decision tree ensemble (e.g., XGBoost or LightGBM) with feature interaction"
    },
    "root_1_0_0_0_1_0_0_0_0": {
      "depth": 9,
      "num_children": 1,
      "score": 0.6483253588516746,
      "strategy": "Replace the gradient-boosted tree ensemble with a neural network architecture incorporating deep lea"
    },
    "root_1_0_0_0_1_0_0_0_0_0": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) architecture where passengers are represented as nodes in a s"
    },
    "root_1_0_0_0_1_0_0_1": {
      "depth": 8,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a gradient-boosted tree ensemble (e.g., LightGBM or XGBoost) with structured feature interacti"
    },
    "root_1_0_0_0_0_1": {
      "depth": 6,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a time-series recurrent model (e.g., LSTM) to capture temporal dynamics in passenger data,"
    },
    "root_1_0_0_0_0_1_0": {
      "depth": 7,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a graph neural network (GNN) with dynamic edge weights to model passenger relationships ba"
    },
    "root_1_0_0_0_0_1_0_0": {
      "depth": 8,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a temporal convolutional network (TCN) with multi-scale attention to model survival as a t"
    },
    "root_1_0_0_0_0_1_0_0_0": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a transformer-based model with temporal encoding of passenger boarding sequences, where ea"
    },
    "root_1_0_0_0_0_1_1": {
      "depth": 7,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a graph neural network (GNN) with dynamic edge weighting to model passenger interactions b"
    },
    "root_1_0_0_0_0_1_1_0": {
      "depth": 8,
      "num_children": 1,
      "score": 0.8444976076555024,
      "strategy": "Introduce a survival prediction model based on geospatial clustering of passenger boarding locations"
    },
    "root_1_0_0_0_0_1_1_0_0": {
      "depth": 9,
      "num_children": 1,
      "score": 0.8181818181818182,
      "strategy": "Introduce a survival prediction model based on graph-based passenger network analysis, where each pa"
    },
    "root_1_0_0_0_0_1_1_0_0_0": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a survival prediction model based on temporal dynamics of passenger movements using a recu"
    },
    "root_1_0_0_0_0_0_1_1": {
      "depth": 8,
      "num_children": 2,
      "score": 0.8444976076555024,
      "strategy": "Introduce a Temporal Graph Neural Network (TGNN) that models the dynamic evolution of passenger rela"
    },
    "root_1_0_0_0_0_0_1_1_0": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a hybrid of Self-Attention and Recurrent Neural Networks (SARNN) that models both sequenti"
    },
    "root_1_0_0_0_0_1_0_1": {
      "depth": 8,
      "num_children": 1,
      "score": 0.8444976076555024,
      "strategy": "Introduce a spatial-temporal convolutional network (STCNN) that models the Titanic's sinking as a sp"
    },
    "root_1_0_0_0_0_1_0_1_0": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) where each passenger is a node, and edges represent social re"
    },
    "root_1_0_0_0_0_1_1_1": {
      "depth": 8,
      "num_children": 1,
      "score": 0.8444976076555024,
      "strategy": "Introduce a transformer-based attention mechanism over temporal survival sequences, where each passe"
    },
    "root_1_0_0_0_0_1_1_1_0": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) with edge construction based on physical proximity (e.g., sam"
    },
    "root_1_0_0_0_0_0_1_0_1": {
      "depth": 9,
      "num_children": 1,
      "score": 0.8444976076555024,
      "strategy": "Introduce a Survival-Driven Recurrent Feature Transformer (SR-FT) that dynamically learns and update"
    },
    "root_1_0_0_0_0_0_1_0_1_0": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a Graph Neural Network (GNN)-based survival predictor that models passengers as nodes in a"
    },
    "root_1_0_0_0_0_1_0_0_1": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a transformer-based temporal modeling framework with cross-attention over passenger boardi"
    },
    "root_1_0_0_0_0_0_1_1_1": {
      "depth": 9,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a Transformer-based Survival Prediction Model that treats the entire passenger manifest as"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 0.76555,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2",
        "root_3",
        "root_4"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with targeted feature interactions, such",
      "score": 0.84688995215311,
      "actions_count": 6,
      "children": [
        "root_0_0",
        "root_0_1"
      ],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting ensemble (e.g., XGBoost or LightGBM) with targeted categorical encoding (e",
      "score": 0.8492822966507177,
      "actions_count": 7,
      "children": [
        "root_1_0"
      ],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with targeted feature interactions, such",
      "score": 0.8755980861244019,
      "actions_count": 10,
      "children": [
        "root_2_0"
      ],
      "error": null
    },
    "root_3": {
      "node_id": "root_3",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient-boosted tree model (e.g., XGBoost or LightGBM) with targeted feature interactions, ",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_4": {
      "node_id": "root_4",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with target encoding for categorical fea",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_2_0": {
      "node_id": "root_2_0",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Replace the gradient boosting model with a deep neural network (DNN) architecture, incorporating mul",
      "score": 0.361244019138756,
      "actions_count": 4,
      "children": [
        "root_2_0_0"
      ],
      "error": null
    },
    "root_1_0": {
      "node_id": "root_1_0",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "Replace the gradient boosting model with a deep neural network (DNN) architecture using a feedforwar",
      "score": 0.7894736842105263,
      "actions_count": 7,
      "children": [
        "root_1_0_0"
      ],
      "error": null
    },
    "root_0_0": {
      "node_id": "root_0_0",
      "parent_id": "root_0",
      "depth": 2,
      "strategy": "Replace the gradient boosting model with a neural network architecture (e.g., a multi-layer perceptr",
      "score": 0.8421052631578947,
      "actions_count": 13,
      "children": [
        "root_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0": {
      "node_id": "root_0_0_0",
      "parent_id": "root_0_0",
      "depth": 3,
      "strategy": "Replace the neural network with a random forest ensemble that incorporates target encoding of catego",
      "score": 0.8229665071770335,
      "actions_count": 9,
      "children": [
        "root_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0": {
      "node_id": "root_0_0_0_0",
      "parent_id": "root_0_0_0",
      "depth": 4,
      "strategy": "Introduce a gradient-boosted tree model (e.g., XGBoost or LightGBM) with recursive feature eliminati",
      "score": 0.8349282296650717,
      "actions_count": 5,
      "children": [
        "root_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0",
      "parent_id": "root_0_0_0_0",
      "depth": 5,
      "strategy": "Introduce a neural network with a deep architecture (e.g., multi-layer perceptron) and apply batch n",
      "score": 0.8277511961722488,
      "actions_count": 7,
      "children": [
        "root_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0",
      "depth": 6,
      "strategy": "Introduce a graph neural network (GNN) that models passenger relationships as a graph, where nodes r",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28863 input tokens (4096 > 32768 - 28863). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0": {
      "node_id": "root_1_0_0",
      "parent_id": "root_1_0",
      "depth": 3,
      "strategy": "Replace the deep neural network with a random forest ensemble model, incorporating gradient boosting",
      "score": 0.8421052631578947,
      "actions_count": 7,
      "children": [
        "root_1_0_0_0",
        "root_1_0_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0": {
      "node_id": "root_1_0_0_0",
      "parent_id": "root_1_0_0",
      "depth": 4,
      "strategy": "Introduce a Transformer-based model with attention mechanisms to capture complex, long-range depende",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0",
        "root_1_0_0_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0": {
      "node_id": "root_1_0_0_0_0",
      "parent_id": "root_1_0_0_0",
      "depth": 5,
      "strategy": "Introduce a Graph Neural Network (GNN) to model passenger relationships as a graph, where nodes repr",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_0",
        "root_1_0_0_0_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0": {
      "node_id": "root_1_0_0_0_0_0",
      "parent_id": "root_1_0_0_0_0",
      "depth": 6,
      "strategy": "Introduce a Recurrent Neural Network (RNN) with a custom memory cell designed to encode temporal dep",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_0_0",
        "root_1_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_0": {
      "node_id": "root_1_0_0_0_0_0_0",
      "parent_id": "root_1_0_0_0_0_0",
      "depth": 7,
      "strategy": "Introduce a LightGBM model trained on engineered features that capture socio-economic gradients (e.g",
      "score": 0.8636363636363636,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_0_0_0",
        "root_1_0_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_0_0": {
      "node_id": "root_1_0_0_0_0_0_0_0",
      "parent_id": "root_1_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Introduce a neural network with an embedding layer for categorical variables (e.g., passenger class,",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29032 input tokens (4096 > 32768 - 29032). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_2_0_0": {
      "node_id": "root_2_0_0",
      "parent_id": "root_2_0",
      "depth": 3,
      "strategy": "Replace the neural network with a random forest ensemble with 100 trees, using permutation feature i",
      "score": 0.8349282296650717,
      "actions_count": 7,
      "children": [
        "root_2_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0": {
      "node_id": "root_2_0_0_0",
      "parent_id": "root_2_0_0",
      "depth": 4,
      "strategy": "Replace the random forest with a gradient boosting model (e.g., XGBoost or LightGBM) and incorporate",
      "score": 0.6363636363636364,
      "actions_count": 16,
      "children": [
        "root_2_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0": {
      "node_id": "root_2_0_0_0_0",
      "parent_id": "root_2_0_0_0",
      "depth": 5,
      "strategy": "Replace the neural network with a support vector machine (SVM) using a radial basis function (RBF) k",
      "score": 0.6578947368421053,
      "actions_count": 4,
      "children": [
        "root_2_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0",
      "depth": 6,
      "strategy": "Replace the SVM with a gradient boosting machine (e.g., XGBoost or LightGBM) and incorporate tree-ba",
      "score": 0.6363636363636364,
      "actions_count": 13,
      "children": [
        "root_2_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0",
      "depth": 7,
      "strategy": "Apply a deep neural network (DNN) with multiple hidden layers and non-linear activation functions (e",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28778 input tokens (4096 > 32768 - 28778). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_0_1": {
      "node_id": "root_0_1",
      "parent_id": "root_0",
      "depth": 2,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a deep feedforward network) and inc",
      "score": null,
      "actions_count": 16,
      "children": [],
      "error": null
    },
    "root_1_0_0_0_0_0_0_1": {
      "node_id": "root_1_0_0_0_0_0_0_1",
      "parent_id": "root_1_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Introduce a Random Forest model trained on time-series features derived from passenger boarding sequ",
      "score": 0.8995215311004785,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_0_0_0_1_0",
        "root_1_0_0_0_0_0_0_1_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_0_1_0": {
      "node_id": "root_1_0_0_0_0_0_0_1_0",
      "parent_id": "root_1_0_0_0_0_0_0_1",
      "depth": 9,
      "strategy": "Introduce a Graph Neural Network (GNN) model where passengers are represented as nodes in a social i",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28971 input tokens (4096 > 32768 - 28971). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_0_0_1_1": {
      "node_id": "root_1_0_0_0_0_0_0_1_1",
      "parent_id": "root_1_0_0_0_0_0_0_1",
      "depth": 9,
      "strategy": "Introduce a Graph Neural Network (GNN) model that treats each passenger as a node in a social intera",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28765 input tokens (4096 > 32768 - 28765). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_0_1": {
      "node_id": "root_1_0_0_0_0_0_1",
      "parent_id": "root_1_0_0_0_0_0",
      "depth": 7,
      "strategy": "Introduce a Graph Autoencoder (GAE) with latent space clustering to model passenger relationships ba",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_0_1_0",
        "root_1_0_0_0_0_0_1_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_1_0": {
      "node_id": "root_1_0_0_0_0_0_1_0",
      "parent_id": "root_1_0_0_0_0_0_1",
      "depth": 8,
      "strategy": "Introduce a Temporal Graph Neural Network (TGNN) that models passenger interactions over time (e.g.,",
      "score": 0.8444976076555024,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_0_0_1_0_0",
        "root_1_0_0_0_0_0_1_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_1_0_0": {
      "node_id": "root_1_0_0_0_0_0_1_0_0",
      "parent_id": "root_1_0_0_0_0_0_1_0",
      "depth": 9,
      "strategy": "Introduce a physics-informed neural network (PINN) that models the ship's structural dynamics and en",
      "score": 0.8444976076555024,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_0_0_1_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_1_0_0_0": {
      "node_id": "root_1_0_0_0_0_0_1_0_0_0",
      "parent_id": "root_1_0_0_0_0_0_1_0_0",
      "depth": 10,
      "strategy": "Introduce a graph neural network (GNN) that models passengers as nodes in a social network, where ed",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28767 input tokens (4096 > 32768 - 28767). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_1": {
      "node_id": "root_1_0_0_1",
      "parent_id": "root_1_0_0",
      "depth": 4,
      "strategy": "Introduce a transformer-based model with attention mechanisms to capture long-range dependencies in ",
      "score": 0.937799043062201,
      "actions_count": 7,
      "children": [
        "root_1_0_0_1_0"
      ],
      "error": null
    },
    "root_1_0_0_1_0": {
      "node_id": "root_1_0_0_1_0",
      "parent_id": "root_1_0_0_1",
      "depth": 5,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships as a social network, where n",
      "score": 0.6363636363636364,
      "actions_count": 7,
      "children": [
        "root_1_0_0_1_0_0"
      ],
      "error": null
    },
    "root_1_0_0_1_0_0": {
      "node_id": "root_1_0_0_1_0_0",
      "parent_id": "root_1_0_0_1_0",
      "depth": 6,
      "strategy": "Introduce a spatial-temporal transformer model that treats the ship's deck layout and cabin location",
      "score": 0.6363636363636364,
      "actions_count": 3,
      "children": [
        "root_1_0_0_1_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_1_0_0_0": {
      "node_id": "root_1_0_0_1_0_0_0",
      "parent_id": "root_1_0_0_1_0_0",
      "depth": 7,
      "strategy": "Introduce a graph neural network (GNN) that models passenger survival based on social network struct",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29221 input tokens (4096 > 32768 - 29221). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_1": {
      "node_id": "root_1_0_0_0_1",
      "parent_id": "root_1_0_0_0",
      "depth": 5,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships as a social network, where e",
      "score": 0.8373205741626795,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_1_0"
      ],
      "error": null
    },
    "root_1_0_0_0_1_0": {
      "node_id": "root_1_0_0_0_1_0",
      "parent_id": "root_1_0_0_0_1",
      "depth": 6,
      "strategy": "Introduce a transformer-based model with a tabular input encoder that treats passenger features as a",
      "score": 0.8373205741626795,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_1_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_1_0_0": {
      "node_id": "root_1_0_0_0_1_0_0",
      "parent_id": "root_1_0_0_0_1_0",
      "depth": 7,
      "strategy": "Replace the transformer-based tabular encoder with a Bayesian Neural Network (BNN) that incorporates",
      "score": 0.8373205741626795,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_1_0_0_0",
        "root_1_0_0_0_1_0_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_1_0_0_0": {
      "node_id": "root_1_0_0_0_1_0_0_0",
      "parent_id": "root_1_0_0_0_1_0_0",
      "depth": 8,
      "strategy": "Apply a gradient-boosted decision tree ensemble (e.g., XGBoost or LightGBM) with feature interaction",
      "score": 0.8516746411483254,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_1_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_1_0_0_0_0": {
      "node_id": "root_1_0_0_0_1_0_0_0_0",
      "parent_id": "root_1_0_0_0_1_0_0_0",
      "depth": 9,
      "strategy": "Replace the gradient-boosted tree ensemble with a neural network architecture incorporating deep lea",
      "score": 0.6483253588516746,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_1_0_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_1_0_0_0_0_0": {
      "node_id": "root_1_0_0_0_1_0_0_0_0_0",
      "parent_id": "root_1_0_0_0_1_0_0_0_0",
      "depth": 10,
      "strategy": "Introduce a graph neural network (GNN) architecture where passengers are represented as nodes in a s",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28923 input tokens (4096 > 32768 - 28923). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_1_0_0_1": {
      "node_id": "root_1_0_0_0_1_0_0_1",
      "parent_id": "root_1_0_0_0_1_0_0",
      "depth": 8,
      "strategy": "Apply a gradient-boosted tree ensemble (e.g., LightGBM or XGBoost) with structured feature interacti",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 32500 input tokens (4096 > 32768 - 32500). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_1": {
      "node_id": "root_1_0_0_0_0_1",
      "parent_id": "root_1_0_0_0_0",
      "depth": 6,
      "strategy": "Introduce a time-series recurrent model (e.g., LSTM) to capture temporal dynamics in passenger data,",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_1_0",
        "root_1_0_0_0_0_1_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_0": {
      "node_id": "root_1_0_0_0_0_1_0",
      "parent_id": "root_1_0_0_0_0_1",
      "depth": 7,
      "strategy": "Introduce a graph neural network (GNN) with dynamic edge weights to model passenger relationships ba",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_1_0_0",
        "root_1_0_0_0_0_1_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_0_0": {
      "node_id": "root_1_0_0_0_0_1_0_0",
      "parent_id": "root_1_0_0_0_0_1_0",
      "depth": 8,
      "strategy": "Introduce a temporal convolutional network (TCN) with multi-scale attention to model survival as a t",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_1_0_0_0",
        "root_1_0_0_0_0_1_0_0_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_0_0_0": {
      "node_id": "root_1_0_0_0_0_1_0_0_0",
      "parent_id": "root_1_0_0_0_0_1_0_0",
      "depth": 9,
      "strategy": "Introduce a transformer-based model with temporal encoding of passenger boarding sequences, where ea",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29109 input tokens (4096 > 32768 - 29109). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_1_1": {
      "node_id": "root_1_0_0_0_0_1_1",
      "parent_id": "root_1_0_0_0_0_1",
      "depth": 7,
      "strategy": "Introduce a graph neural network (GNN) with dynamic edge weighting to model passenger interactions b",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_1_1_0",
        "root_1_0_0_0_0_1_1_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_1_0": {
      "node_id": "root_1_0_0_0_0_1_1_0",
      "parent_id": "root_1_0_0_0_0_1_1",
      "depth": 8,
      "strategy": "Introduce a survival prediction model based on geospatial clustering of passenger boarding locations",
      "score": 0.8444976076555024,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_0_1_1_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_1_0_0": {
      "node_id": "root_1_0_0_0_0_1_1_0_0",
      "parent_id": "root_1_0_0_0_0_1_1_0",
      "depth": 9,
      "strategy": "Introduce a survival prediction model based on graph-based passenger network analysis, where each pa",
      "score": 0.8181818181818182,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_0_1_1_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_1_0_0_0": {
      "node_id": "root_1_0_0_0_0_1_1_0_0_0",
      "parent_id": "root_1_0_0_0_0_1_1_0_0",
      "depth": 10,
      "strategy": "Introduce a survival prediction model based on temporal dynamics of passenger movements using a recu",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28740 input tokens (4096 > 32768 - 28740). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_0_1_1": {
      "node_id": "root_1_0_0_0_0_0_1_1",
      "parent_id": "root_1_0_0_0_0_0_1",
      "depth": 8,
      "strategy": "Introduce a Temporal Graph Neural Network (TGNN) that models the dynamic evolution of passenger rela",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_0_1_1_0",
        "root_1_0_0_0_0_0_1_1_1"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_1_1_0": {
      "node_id": "root_1_0_0_0_0_0_1_1_0",
      "parent_id": "root_1_0_0_0_0_0_1_1",
      "depth": 9,
      "strategy": "Introduce a hybrid of Self-Attention and Recurrent Neural Networks (SARNN) that models both sequenti",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29033 input tokens (4096 > 32768 - 29033). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_1_0_1": {
      "node_id": "root_1_0_0_0_0_1_0_1",
      "parent_id": "root_1_0_0_0_0_1_0",
      "depth": 8,
      "strategy": "Introduce a spatial-temporal convolutional network (STCNN) that models the Titanic's sinking as a sp",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_1_0_1_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_0_1_0": {
      "node_id": "root_1_0_0_0_0_1_0_1_0",
      "parent_id": "root_1_0_0_0_0_1_0_1",
      "depth": 9,
      "strategy": "Introduce a graph neural network (GNN) where each passenger is a node, and edges represent social re",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29133 input tokens (4096 > 32768 - 29133). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_1_1_1": {
      "node_id": "root_1_0_0_0_0_1_1_1",
      "parent_id": "root_1_0_0_0_0_1_1",
      "depth": 8,
      "strategy": "Introduce a transformer-based attention mechanism over temporal survival sequences, where each passe",
      "score": 0.8444976076555024,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0_0_1_1_1_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_1_1_1_0": {
      "node_id": "root_1_0_0_0_0_1_1_1_0",
      "parent_id": "root_1_0_0_0_0_1_1_1",
      "depth": 9,
      "strategy": "Introduce a graph neural network (GNN) with edge construction based on physical proximity (e.g., sam",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29167 input tokens (4096 > 32768 - 29167). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_0_1_0_1": {
      "node_id": "root_1_0_0_0_0_0_1_0_1",
      "parent_id": "root_1_0_0_0_0_0_1_0",
      "depth": 9,
      "strategy": "Introduce a Survival-Driven Recurrent Feature Transformer (SR-FT) that dynamically learns and update",
      "score": 0.8444976076555024,
      "actions_count": 3,
      "children": [
        "root_1_0_0_0_0_0_1_0_1_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_1_0_1_0": {
      "node_id": "root_1_0_0_0_0_0_1_0_1_0",
      "parent_id": "root_1_0_0_0_0_0_1_0_1",
      "depth": 10,
      "strategy": "Introduce a Graph Neural Network (GNN)-based survival predictor that models passengers as nodes in a",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28874 input tokens (4096 > 32768 - 28874). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_1_0_0_1": {
      "node_id": "root_1_0_0_0_0_1_0_0_1",
      "parent_id": "root_1_0_0_0_0_1_0_0",
      "depth": 9,
      "strategy": "Introduce a transformer-based temporal modeling framework with cross-attention over passenger boardi",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29136 input tokens (4096 > 32768 - 29136). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0_0_0_0_0_1_1_1": {
      "node_id": "root_1_0_0_0_0_0_1_1_1",
      "parent_id": "root_1_0_0_0_0_0_1_1",
      "depth": 9,
      "strategy": "Introduce a Transformer-based Survival Prediction Model that treats the entire passenger manifest as",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29080 input tokens (4096 > 32768 - 29080). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    }
  }
}