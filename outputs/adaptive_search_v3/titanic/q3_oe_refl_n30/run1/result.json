{
  "task": "Titanic Survival Prediction",
  "primary_metric": "accuracy",
  "higher_is_better": true,
  "selection_strategy": "open-ended",
  "best_node_id": "root_0_0_0_0_0_0_1",
  "best_score": 0.9545454545454546,
  "baseline_score": 0.76555,
  "improvement": 0.18899545454545463,
  "total_nodes": 31,
  "elapsed_seconds": 5649.5,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 3,
      "score": 0.76555,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 1,
      "score": 0.638755980861244,
      "strategy": "Apply a gradient boosting ensemble (e.g., XGBoost or LightGBM) with categorical features encoded usi"
    },
    "root_1": {
      "depth": 1,
      "num_children": 1,
      "score": 0.6220095693779905,
      "strategy": "Apply a gradient-boosted tree model (e.g., LightGBM or XGBoost) with targeted feature interactions, "
    },
    "root_2": {
      "depth": 1,
      "num_children": 1,
      "score": 0.8755980861244019,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with categorical feature binning and tar"
    },
    "root_2_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.8636363636363636,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a deep feedforward network) using a"
    },
    "root_2_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.6555023923444976,
      "strategy": "Introduce a random forest ensemble with permutation importance-based feature selection to identify t"
    },
    "root_2_0_0_0": {
      "depth": 4,
      "num_children": 0,
      "score": null,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with target encoding for categorical var"
    },
    "root_0_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.8803827751196173,
      "strategy": "Replace the gradient boosting model with a neural network architecture (e.g., a multi-layer perceptr"
    },
    "root_0_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.8564593301435407,
      "strategy": "Apply a random forest ensemble with feature bagging and bootstrap aggregation, but introduce targete"
    },
    "root_0_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.638755980861244,
      "strategy": "Replace the random forest ensemble with a gradient boosting machine (e.g., XGBoost or LightGBM) usin"
    },
    "root_0_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 0.9066985645933014,
      "strategy": "Apply a neural network with a deep architecture (e.g., 3\u20135 hidden layers) using a feedforward neural"
    },
    "root_0_0_0_0_0_0": {
      "depth": 6,
      "num_children": 2,
      "score": 0.9066985645933014,
      "strategy": "Replace the neural network with a gradient boosting ensemble (e.g., XGBoost or LightGBM) using tree-"
    },
    "root_0_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 2,
      "score": 0.930622009569378,
      "strategy": "Replace the gradient boosting model with a deep autoencoder-based generative model to learn latent r"
    },
    "root_0_0_0_0_0_0_0_0": {
      "depth": 8,
      "num_children": 2,
      "score": 0.930622009569378,
      "strategy": "Replace the deep autoencoder with a contrastive learning framework (e.g., SimCLR or MoCo) to learn r"
    },
    "root_0_0_0_0_0_0_0_0_0": {
      "depth": 9,
      "num_children": 2,
      "score": 0.930622009569378,
      "strategy": "Introduce a graph neural network (GNN) framework where passengers are represented as nodes in a soci"
    },
    "root_0_0_0_0_0_0_0_0_0_0": {
      "depth": 10,
      "num_children": 1,
      "score": 0.930622009569378,
      "strategy": "Introduce a time-series modeling approach by treating the survival outcome as a function of sequenti"
    },
    "root_0_0_0_0_0_0_0_0_0_0_0": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) with a dynamic edge-based model that represents passengers as"
    },
    "root_1_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.8564593301435407,
      "strategy": "Replace the gradient-boosted tree model with a neural network architecture (e.g., a multi-layer perc"
    },
    "root_1_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.84688995215311,
      "strategy": "Replace the neural network with a random forest ensemble, where each tree is trained on a bootstrapp"
    },
    "root_1_0_0_0": {
      "depth": 4,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a support vector machine (SVM) with a radial basis function (RBF) kernel, trained on a fea"
    },
    "root_0_0_0_0_0_0_1": {
      "depth": 7,
      "num_children": 2,
      "score": 0.9545454545454546,
      "strategy": "Introduce a deep autoencoder-based feature learning pipeline to extract latent representations from "
    },
    "root_0_0_0_0_0_0_1_0": {
      "depth": 8,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a contrastive learning framework where survival labels are used to define positive and neg"
    },
    "root_0_0_0_0_0_0_1_1": {
      "depth": 8,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships as a social network, where n"
    },
    "root_0_0_0_0_0_0_0_1": {
      "depth": 8,
      "num_children": 1,
      "score": 0.9066985645933014,
      "strategy": "Replace the deep autoencoder with a time-series transformer model that processes passenger data in s"
    },
    "root_0_0_0_0_0_0_0_1_0": {
      "depth": 9,
      "num_children": 1,
      "score": 0.9066985645933014,
      "strategy": "Apply a graph neural network (GNN) to model passengers as nodes in a social network, where edges rep"
    },
    "root_0_0_0_0_0_0_0_1_0_0": {
      "depth": 10,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a transformer-based model that treats the passenger data as a sequence of structured event"
    },
    "root_0_0_0_0_0_0_0_0_1": {
      "depth": 9,
      "num_children": 1,
      "score": 0.930622009569378,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships based on categorical feature"
    },
    "root_0_0_0_0_0_0_0_0_1_0": {
      "depth": 10,
      "num_children": 1,
      "score": 0.930622009569378,
      "strategy": "Introduce a transformer-based model with self-attention over passenger records, where each passenger"
    },
    "root_0_0_0_0_0_0_0_0_1_0_0": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with custom feature engineeri"
    },
    "root_0_0_0_0_0_0_0_0_0_1": {
      "depth": 10,
      "num_children": 1,
      "score": 0.930622009569378,
      "strategy": "Introduce a temporal graph network (TGN) where passenger interactions are modeled over time (e.g., b"
    },
    "root_0_0_0_0_0_0_0_0_0_1_0": {
      "depth": 11,
      "num_children": 0,
      "score": null,
      "strategy": "Introduce a physics-informed neural network (PINN) that models the physical dynamics of the ship's s"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 0.76555,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting ensemble (e.g., XGBoost or LightGBM) with categorical features encoded usi",
      "score": 0.638755980861244,
      "actions_count": 6,
      "children": [
        "root_0_0"
      ],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient-boosted tree model (e.g., LightGBM or XGBoost) with targeted feature interactions, ",
      "score": 0.6220095693779905,
      "actions_count": 12,
      "children": [
        "root_1_0"
      ],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with categorical feature binning and tar",
      "score": 0.8755980861244019,
      "actions_count": 9,
      "children": [
        "root_2_0"
      ],
      "error": null
    },
    "root_2_0": {
      "node_id": "root_2_0",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Replace the gradient boosting model with a neural network (e.g., a deep feedforward network) using a",
      "score": 0.8636363636363636,
      "actions_count": 6,
      "children": [
        "root_2_0_0"
      ],
      "error": null
    },
    "root_2_0_0": {
      "node_id": "root_2_0_0",
      "parent_id": "root_2_0",
      "depth": 3,
      "strategy": "Introduce a random forest ensemble with permutation importance-based feature selection to identify t",
      "score": 0.6555023923444976,
      "actions_count": 5,
      "children": [
        "root_2_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0": {
      "node_id": "root_2_0_0_0",
      "parent_id": "root_2_0_0",
      "depth": 4,
      "strategy": "Apply a gradient boosting model (e.g., XGBoost or LightGBM) with target encoding for categorical var",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29396 input tokens (4096 > 32768 - 29396). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_0_0": {
      "node_id": "root_0_0",
      "parent_id": "root_0",
      "depth": 2,
      "strategy": "Replace the gradient boosting model with a neural network architecture (e.g., a multi-layer perceptr",
      "score": 0.8803827751196173,
      "actions_count": 9,
      "children": [
        "root_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0": {
      "node_id": "root_0_0_0",
      "parent_id": "root_0_0",
      "depth": 3,
      "strategy": "Apply a random forest ensemble with feature bagging and bootstrap aggregation, but introduce targete",
      "score": 0.8564593301435407,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0": {
      "node_id": "root_0_0_0_0",
      "parent_id": "root_0_0_0",
      "depth": 4,
      "strategy": "Replace the random forest ensemble with a gradient boosting machine (e.g., XGBoost or LightGBM) usin",
      "score": 0.638755980861244,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0",
      "parent_id": "root_0_0_0_0",
      "depth": 5,
      "strategy": "Apply a neural network with a deep architecture (e.g., 3\u20135 hidden layers) using a feedforward neural",
      "score": 0.9066985645933014,
      "actions_count": 5,
      "children": [
        "root_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0",
      "depth": 6,
      "strategy": "Replace the neural network with a gradient boosting ensemble (e.g., XGBoost or LightGBM) using tree-",
      "score": 0.9066985645933014,
      "actions_count": 5,
      "children": [
        "root_0_0_0_0_0_0_0",
        "root_0_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0",
      "depth": 7,
      "strategy": "Replace the gradient boosting model with a deep autoencoder-based generative model to learn latent r",
      "score": 0.930622009569378,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_0",
        "root_0_0_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Replace the deep autoencoder with a contrastive learning framework (e.g., SimCLR or MoCo) to learn r",
      "score": 0.930622009569378,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_0_0",
        "root_0_0_0_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0",
      "depth": 9,
      "strategy": "Introduce a graph neural network (GNN) framework where passengers are represented as nodes in a soci",
      "score": 0.930622009569378,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0",
        "root_0_0_0_0_0_0_0_0_0_1"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0",
      "depth": 10,
      "strategy": "Introduce a time-series modeling approach by treating the survival outcome as a function of sequenti",
      "score": 0.930622009569378,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_0",
      "depth": 11,
      "strategy": "Introduce a graph neural network (GNN) with a dynamic edge-based model that represents passengers as",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28871 input tokens (4096 > 32768 - 28871). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_1_0": {
      "node_id": "root_1_0",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "Replace the gradient-boosted tree model with a neural network architecture (e.g., a multi-layer perc",
      "score": 0.8564593301435407,
      "actions_count": 9,
      "children": [
        "root_1_0_0"
      ],
      "error": null
    },
    "root_1_0_0": {
      "node_id": "root_1_0_0",
      "parent_id": "root_1_0",
      "depth": 3,
      "strategy": "Replace the neural network with a random forest ensemble, where each tree is trained on a bootstrapp",
      "score": 0.84688995215311,
      "actions_count": 5,
      "children": [
        "root_1_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0": {
      "node_id": "root_1_0_0_0",
      "parent_id": "root_1_0_0",
      "depth": 4,
      "strategy": "Introduce a support vector machine (SVM) with a radial basis function (RBF) kernel, trained on a fea",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29575 input tokens (4096 > 32768 - 29575). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_0_0_0_0_0_0_1": {
      "node_id": "root_0_0_0_0_0_0_1",
      "parent_id": "root_0_0_0_0_0_0",
      "depth": 7,
      "strategy": "Introduce a deep autoencoder-based feature learning pipeline to extract latent representations from ",
      "score": 0.9545454545454546,
      "actions_count": 9,
      "children": [
        "root_0_0_0_0_0_0_1_0",
        "root_0_0_0_0_0_0_1_1"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_1_0": {
      "node_id": "root_0_0_0_0_0_0_1_0",
      "parent_id": "root_0_0_0_0_0_0_1",
      "depth": 8,
      "strategy": "Introduce a contrastive learning framework where survival labels are used to define positive and neg",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28937 input tokens (4096 > 32768 - 28937). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_0_0_0_0_0_0_1_1": {
      "node_id": "root_0_0_0_0_0_0_1_1",
      "parent_id": "root_0_0_0_0_0_0_1",
      "depth": 8,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships as a social network, where n",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28739 input tokens (4096 > 32768 - 28739). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_0_0_0_0_0_0_0_1": {
      "node_id": "root_0_0_0_0_0_0_0_1",
      "parent_id": "root_0_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Replace the deep autoencoder with a time-series transformer model that processes passenger data in s",
      "score": 0.9066985645933014,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_1_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_1_0": {
      "node_id": "root_0_0_0_0_0_0_0_1_0",
      "parent_id": "root_0_0_0_0_0_0_0_1",
      "depth": 9,
      "strategy": "Apply a graph neural network (GNN) to model passengers as nodes in a social network, where edges rep",
      "score": 0.9066985645933014,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_1_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_1_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_1_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_1_0",
      "depth": 10,
      "strategy": "Introduce a transformer-based model that treats the passenger data as a sequence of structured event",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28925 input tokens (4096 > 32768 - 28925). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_0_0_0_0_0_0_0_0_1": {
      "node_id": "root_0_0_0_0_0_0_0_0_1",
      "parent_id": "root_0_0_0_0_0_0_0_0",
      "depth": 9,
      "strategy": "Introduce a graph neural network (GNN) to model passenger relationships based on categorical feature",
      "score": 0.930622009569378,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_0_1_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_1_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_1_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_1",
      "depth": 10,
      "strategy": "Introduce a transformer-based model with self-attention over passenger records, where each passenger",
      "score": 0.930622009569378,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_0_1_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_1_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_1_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_1_0",
      "depth": 11,
      "strategy": "Introduce a gradient-boosted tree ensemble (e.g., XGBoost or LightGBM) with custom feature engineeri",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 29265 input tokens (4096 > 32768 - 29265). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    },
    "root_0_0_0_0_0_0_0_0_0_1": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_1",
      "parent_id": "root_0_0_0_0_0_0_0_0_0",
      "depth": 10,
      "strategy": "Introduce a temporal graph network (TGN) where passenger interactions are modeled over time (e.g., b",
      "score": 0.930622009569378,
      "actions_count": 3,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_1_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_1_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_1_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_1",
      "depth": 11,
      "strategy": "Introduce a physics-informed neural network (PINN) that models the physical dynamics of the ship's s",
      "score": null,
      "actions_count": 0,
      "children": [],
      "error": "LLM failed: LLM failed after 3 attempts: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 32768 tokens and your request has 28969 input tokens (4096 > 32768 - 28969). (parameter=max_tokens, value=4096) None\", 'type': 'BadRequestError', 'param': None, 'code': 400}}"
    }
  }
}