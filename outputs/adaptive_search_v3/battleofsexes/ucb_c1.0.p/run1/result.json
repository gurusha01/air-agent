{
  "task": "Battle of Sexes",
  "primary_metric": "Score",
  "higher_is_better": true,
  "selection_strategy": "ucb",
  "best_node_id": "root_2_0_0_0_0_0_0_0",
  "best_score": 1.4422399997711182,
  "baseline_score": 0.0,
  "improvement": 1.4422399997711182,
  "total_nodes": 13,
  "elapsed_seconds": 192.9,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 3,
      "score": 0.0,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 0,
      "score": 0.723580002784729,
      "strategy": "Adopt a mixed strategy where the row player chooses \"Coordination\" with a probability of 0.6 and \"Co"
    },
    "root_1": {
      "depth": 1,
      "num_children": 1,
      "score": 1.0624700784683228,
      "strategy": "Adopt a mixed strategy where the row player chooses \"cooperate\" with probability 0.7 and \"defect\" wi"
    },
    "root_2": {
      "depth": 1,
      "num_children": 1,
      "score": 0.9348599314689636,
      "strategy": "Adopt a time-varying mixed strategy where the row player randomizes between coordinating with the co"
    },
    "root_1_0": {
      "depth": 2,
      "num_children": 0,
      "score": 0.6432600021362305,
      "strategy": "The row player adopts a time-varying mixed strategy based on a moving average of the column player's"
    },
    "root_2_0": {
      "depth": 2,
      "num_children": 1,
      "score": 1.2072298526763916,
      "strategy": "Implement a sinusoidal time-varying mixed strategy where the probability of coordination oscillates "
    },
    "root_2_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.8372299671173096,
      "strategy": "Implement a piecewise-constant mixed strategy with adaptive threshold switching based on the opponen"
    },
    "root_2_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.9248200058937073,
      "strategy": "Implement a time-varying sinusoidal coordination strategy where the probability of coordination is m"
    },
    "root_2_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 1.2292400598526,
      "strategy": "Implement a fractal-based coordination strategy where the coordination probability is derived from a"
    },
    "root_2_0_0_0_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 1.215579867362976,
      "strategy": "Implement a quantum-inspired entanglement strategy where the coordination probability is determined "
    },
    "root_2_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 1,
      "score": 1.4396201372146606,
      "strategy": "Adopt a temporal reinforcement learning (TDL) strategy where the row player learns a reward function"
    },
    "root_2_0_0_0_0_0_0_0": {
      "depth": 8,
      "num_children": 1,
      "score": 1.4422399997711182,
      "strategy": "Introduce a context-aware action selection mechanism using a sliding-window correlation matrix that "
    },
    "root_2_0_0_0_0_0_0_0_0": {
      "depth": 9,
      "num_children": 0,
      "score": 1.0185201168060303,
      "strategy": "Introduce a phase-based action cycling mechanism where the row player alternates between two actions"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 0.0,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Adopt a mixed strategy where the row player chooses \"Coordination\" with a probability of 0.6 and \"Co",
      "score": 0.723580002784729,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Adopt a mixed strategy where the row player chooses \"cooperate\" with probability 0.7 and \"defect\" wi",
      "score": 1.0624700784683228,
      "actions_count": 2,
      "children": [
        "root_1_0"
      ],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Adopt a time-varying mixed strategy where the row player randomizes between coordinating with the co",
      "score": 0.9348599314689636,
      "actions_count": 2,
      "children": [
        "root_2_0"
      ],
      "error": null
    },
    "root_1_0": {
      "node_id": "root_1_0",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "The row player adopts a time-varying mixed strategy based on a moving average of the column player's",
      "score": 0.6432600021362305,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_2_0": {
      "node_id": "root_2_0",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Implement a sinusoidal time-varying mixed strategy where the probability of coordination oscillates ",
      "score": 1.2072298526763916,
      "actions_count": 2,
      "children": [
        "root_2_0_0"
      ],
      "error": null
    },
    "root_2_0_0": {
      "node_id": "root_2_0_0",
      "parent_id": "root_2_0",
      "depth": 3,
      "strategy": "Implement a piecewise-constant mixed strategy with adaptive threshold switching based on the opponen",
      "score": 0.8372299671173096,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0": {
      "node_id": "root_2_0_0_0",
      "parent_id": "root_2_0_0",
      "depth": 4,
      "strategy": "Implement a time-varying sinusoidal coordination strategy where the probability of coordination is m",
      "score": 0.9248200058937073,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0": {
      "node_id": "root_2_0_0_0_0",
      "parent_id": "root_2_0_0_0",
      "depth": 5,
      "strategy": "Implement a fractal-based coordination strategy where the coordination probability is derived from a",
      "score": 1.2292400598526,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0",
      "depth": 6,
      "strategy": "Implement a quantum-inspired entanglement strategy where the coordination probability is determined ",
      "score": 1.215579867362976,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0",
      "depth": 7,
      "strategy": "Adopt a temporal reinforcement learning (TDL) strategy where the row player learns a reward function",
      "score": 1.4396201372146606,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Introduce a context-aware action selection mechanism using a sliding-window correlation matrix that ",
      "score": 1.4422399997711182,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0_0_0",
      "depth": 9,
      "strategy": "Introduce a phase-based action cycling mechanism where the row player alternates between two actions",
      "score": 1.0185201168060303,
      "actions_count": 2,
      "children": [],
      "error": null
    }
  }
}