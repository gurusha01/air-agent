{
  "task": "Battle of Sexes",
  "primary_metric": "Score",
  "higher_is_better": true,
  "selection_strategy": "ucb",
  "best_node_id": "root_1_0_0_0_0",
  "best_score": 1.4393799304962158,
  "baseline_score": 0.0,
  "improvement": 1.4393799304962158,
  "total_nodes": 13,
  "elapsed_seconds": 301.5,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 3,
      "score": 0.0,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 0,
      "score": 0.8025799989700317,
      "strategy": "Adopt a randomized commitment strategy where the row player selects \"Home\" with probability 0.6 and "
    },
    "root_1": {
      "depth": 1,
      "num_children": 1,
      "score": 0.8048299551010132,
      "strategy": "Randomized mixed strategy where the row player chooses 'Action A' with probability 0.6 and 'Action B"
    },
    "root_2": {
      "depth": 1,
      "num_children": 1,
      "score": 1.0305101871490479,
      "strategy": "Adopt a time-varying mixed strategy where the row player randomizes between coordinating on the pref"
    },
    "root_2_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.9105299711227417,
      "strategy": "Implement a dynamic payoff-weighted strategy where the row player adjusts their choice based on the "
    },
    "root_2_0_0": {
      "depth": 3,
      "num_children": 0,
      "score": 0.7879700064659119,
      "strategy": "Implement a temporal difference learning (TD-learning) strategy where the row player updates their c"
    },
    "root_1_0": {
      "depth": 2,
      "num_children": 1,
      "score": 1.3152700662612915,
      "strategy": "Implement a payoff-weighted adaptive mixed strategy where the row player selects Action A with proba"
    },
    "root_1_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.8161300420761108,
      "strategy": "Implement a temporal difference (TD) learning strategy where the row player estimates the value of e"
    },
    "root_1_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 1.3558800220489502,
      "strategy": "Implement a reinforcement learning strategy using a Q-learning framework with epsilon-greedy explora"
    },
    "root_1_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 1.4393799304962158,
      "strategy": "Implement a temporal difference learning strategy with a moving average of past rewards, where the r"
    },
    "root_1_0_0_0_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.8885599374771118,
      "strategy": "Implement a Bayesian updating strategy with conjugate priors where the row player maintains a poster"
    },
    "root_1_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 1,
      "score": 0.9701299667358398,
      "strategy": "Implement a reinforcement learning strategy using a Q-learning framework where the row player learns"
    },
    "root_1_0_0_0_0_0_0_0": {
      "depth": 8,
      "num_children": 0,
      "score": 0.809909999370575,
      "strategy": "Implement a contextual bandit strategy where the row player observes the opponent's previous action "
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 0.0,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Adopt a randomized commitment strategy where the row player selects \"Home\" with probability 0.6 and ",
      "score": 0.8025799989700317,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Randomized mixed strategy where the row player chooses 'Action A' with probability 0.6 and 'Action B",
      "score": 0.8048299551010132,
      "actions_count": 2,
      "children": [
        "root_1_0"
      ],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Adopt a time-varying mixed strategy where the row player randomizes between coordinating on the pref",
      "score": 1.0305101871490479,
      "actions_count": 2,
      "children": [
        "root_2_0"
      ],
      "error": null
    },
    "root_2_0": {
      "node_id": "root_2_0",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Implement a dynamic payoff-weighted strategy where the row player adjusts their choice based on the ",
      "score": 0.9105299711227417,
      "actions_count": 2,
      "children": [
        "root_2_0_0"
      ],
      "error": null
    },
    "root_2_0_0": {
      "node_id": "root_2_0_0",
      "parent_id": "root_2_0",
      "depth": 3,
      "strategy": "Implement a temporal difference learning (TD-learning) strategy where the row player updates their c",
      "score": 0.7879700064659119,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_1_0": {
      "node_id": "root_1_0",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "Implement a payoff-weighted adaptive mixed strategy where the row player selects Action A with proba",
      "score": 1.3152700662612915,
      "actions_count": 2,
      "children": [
        "root_1_0_0"
      ],
      "error": null
    },
    "root_1_0_0": {
      "node_id": "root_1_0_0",
      "parent_id": "root_1_0",
      "depth": 3,
      "strategy": "Implement a temporal difference (TD) learning strategy where the row player estimates the value of e",
      "score": 0.8161300420761108,
      "actions_count": 2,
      "children": [
        "root_1_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0": {
      "node_id": "root_1_0_0_0",
      "parent_id": "root_1_0_0",
      "depth": 4,
      "strategy": "Implement a reinforcement learning strategy using a Q-learning framework with epsilon-greedy explora",
      "score": 1.3558800220489502,
      "actions_count": 4,
      "children": [
        "root_1_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0": {
      "node_id": "root_1_0_0_0_0",
      "parent_id": "root_1_0_0_0",
      "depth": 5,
      "strategy": "Implement a temporal difference learning strategy with a moving average of past rewards, where the r",
      "score": 1.4393799304962158,
      "actions_count": 12,
      "children": [
        "root_1_0_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0": {
      "node_id": "root_1_0_0_0_0_0",
      "parent_id": "root_1_0_0_0_0",
      "depth": 6,
      "strategy": "Implement a Bayesian updating strategy with conjugate priors where the row player maintains a poster",
      "score": 0.8885599374771118,
      "actions_count": 2,
      "children": [
        "root_1_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_0": {
      "node_id": "root_1_0_0_0_0_0_0",
      "parent_id": "root_1_0_0_0_0_0",
      "depth": 7,
      "strategy": "Implement a reinforcement learning strategy using a Q-learning framework where the row player learns",
      "score": 0.9701299667358398,
      "actions_count": 2,
      "children": [
        "root_1_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0_0_0_0": {
      "node_id": "root_1_0_0_0_0_0_0_0",
      "parent_id": "root_1_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Implement a contextual bandit strategy where the row player observes the opponent's previous action ",
      "score": 0.809909999370575,
      "actions_count": 2,
      "children": [],
      "error": null
    }
  }
}