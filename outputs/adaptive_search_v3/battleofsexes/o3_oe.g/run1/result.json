{
  "task": "Battle of Sexes",
  "primary_metric": "Score",
  "higher_is_better": true,
  "selection_strategy": "open-ended",
  "best_node_id": "root_1",
  "best_score": 1.4423600435256958,
  "baseline_score": 1.0226699113845825,
  "improvement": 0.4196901321411133,
  "total_nodes": 13,
  "elapsed_seconds": 872.6,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 3,
      "score": 1.0226699113845825,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 1,
      "score": 1.4348400831222534,
      "strategy": "Bayesian-exploration & exploitation policy:  \n1. Exploration (first 15 rounds of each match). Play t"
    },
    "root_1": {
      "depth": 1,
      "num_children": 1,
      "score": 1.4423600435256958,
      "strategy": "Bayesian Thompson Sampling: Model the column player\u2019s chance of playing \u201cOpera\u201d vs. \u201cFootball\u201d as a "
    },
    "root_2": {
      "depth": 1,
      "num_children": 1,
      "score": 1.2387499809265137,
      "strategy": "Bayesian-Learning Best-Response:  Model the column player as having an (unknown) fixed mixed strateg"
    },
    "root_1_0": {
      "depth": 2,
      "num_children": 0,
      "score": 1.231429934501648,
      "strategy": "First-order Markov predictor with Dirichlet-TS.  \n1. Track four transition counts N(op_prev\u2192op_now) "
    },
    "root_0_0": {
      "depth": 2,
      "num_children": 0,
      "score": 0.7522199153900146,
      "strategy": "Tabular-Q Learner with \u201cmemory-1\u201d states\n\n1. State space: s\u209c = (my last action, opponent last action"
    },
    "root_2_0": {
      "depth": 2,
      "num_children": 1,
      "score": 1.3648699522018433,
      "strategy": "Adaptive First-Order Markov Predictor with Dynamic Window  \n1. Maintain four counts N\u1d62\u2c7c for opponent"
    },
    "root_2_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 1.2511199712753296,
      "strategy": "Changepoint-Aware Bayesian Learner (CABL)  \n1. Model the opponent as piece-wise stationary: within a"
    },
    "root_2_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 1.440540075302124,
      "strategy": "Strategy: Recency-Weighted n-Gram Ensemble (RWnGE)\n\n1. Feature Bank  \n   \u2022 For each history length n"
    },
    "root_2_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 1.2969499826431274,
      "strategy": "Strategy: Online Periodicity Detector & Phase Aligner (OPD-PA)\n\nIdea  \nMany pilot bots follow short,"
    },
    "root_2_0_0_0_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 1.4410600662231445,
      "strategy": "Strategy: Bayesian Change-Point & Hidden-Bias Thompson Sampler (BCP-HBTS)\n\nCore idea  \nModel the opp"
    },
    "root_2_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 1,
      "score": 1.4152300357818604,
      "strategy": "Strategy: Expert Hedge over Finite-State Predictors (EHFSP)\n\nCore idea  \nInstead of learning paramet"
    },
    "root_2_0_0_0_0_0_0_0": {
      "depth": 8,
      "num_children": 0,
      "score": 1.1932700872421265,
      "strategy": "Bayesian Online Change-Point Thompson Sampling (BOCTS)\n\nIdea\nModel the opponent\u2019s sequence as a succ"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 1.0226699113845825,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Bayesian-exploration & exploitation policy:  \n1. Exploration (first 15 rounds of each match). Play t",
      "score": 1.4348400831222534,
      "actions_count": 2,
      "children": [
        "root_0_0"
      ],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Bayesian Thompson Sampling: Model the column player\u2019s chance of playing \u201cOpera\u201d vs. \u201cFootball\u201d as a ",
      "score": 1.4423600435256958,
      "actions_count": 2,
      "children": [
        "root_1_0"
      ],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Bayesian-Learning Best-Response:  Model the column player as having an (unknown) fixed mixed strateg",
      "score": 1.2387499809265137,
      "actions_count": 2,
      "children": [
        "root_2_0"
      ],
      "error": null
    },
    "root_1_0": {
      "node_id": "root_1_0",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "First-order Markov predictor with Dirichlet-TS.  \n1. Track four transition counts N(op_prev\u2192op_now) ",
      "score": 1.231429934501648,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_0_0": {
      "node_id": "root_0_0",
      "parent_id": "root_0",
      "depth": 2,
      "strategy": "Tabular-Q Learner with \u201cmemory-1\u201d states\n\n1. State space: s\u209c = (my last action, opponent last action",
      "score": 0.7522199153900146,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_2_0": {
      "node_id": "root_2_0",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Adaptive First-Order Markov Predictor with Dynamic Window  \n1. Maintain four counts N\u1d62\u2c7c for opponent",
      "score": 1.3648699522018433,
      "actions_count": 2,
      "children": [
        "root_2_0_0"
      ],
      "error": null
    },
    "root_2_0_0": {
      "node_id": "root_2_0_0",
      "parent_id": "root_2_0",
      "depth": 3,
      "strategy": "Changepoint-Aware Bayesian Learner (CABL)  \n1. Model the opponent as piece-wise stationary: within a",
      "score": 1.2511199712753296,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0": {
      "node_id": "root_2_0_0_0",
      "parent_id": "root_2_0_0",
      "depth": 4,
      "strategy": "Strategy: Recency-Weighted n-Gram Ensemble (RWnGE)\n\n1. Feature Bank  \n   \u2022 For each history length n",
      "score": 1.440540075302124,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0": {
      "node_id": "root_2_0_0_0_0",
      "parent_id": "root_2_0_0_0",
      "depth": 5,
      "strategy": "Strategy: Online Periodicity Detector & Phase Aligner (OPD-PA)\n\nIdea  \nMany pilot bots follow short,",
      "score": 1.2969499826431274,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0",
      "depth": 6,
      "strategy": "Strategy: Bayesian Change-Point & Hidden-Bias Thompson Sampler (BCP-HBTS)\n\nCore idea  \nModel the opp",
      "score": 1.4410600662231445,
      "actions_count": 3,
      "children": [
        "root_2_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0",
      "depth": 7,
      "strategy": "Strategy: Expert Hedge over Finite-State Predictors (EHFSP)\n\nCore idea  \nInstead of learning paramet",
      "score": 1.4152300357818604,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Bayesian Online Change-Point Thompson Sampling (BOCTS)\n\nIdea\nModel the opponent\u2019s sequence as a succ",
      "score": 1.1932700872421265,
      "actions_count": 2,
      "children": [],
      "error": null
    }
  }
}