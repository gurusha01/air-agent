{
  "task": "Battle of Sexes",
  "primary_metric": "Score",
  "higher_is_better": true,
  "selection_strategy": "open-ended",
  "best_node_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0",
  "best_score": 1.4368400573730469,
  "baseline_score": 1.0226699113845825,
  "improvement": 0.41417014598846436,
  "total_nodes": 31,
  "elapsed_seconds": 427.9,
  "tree_shape": {
    "root": {
      "depth": 0,
      "num_children": 3,
      "score": 1.0226699113845825,
      "strategy": "Baseline (no model execution)"
    },
    "root_0": {
      "depth": 1,
      "num_children": 1,
      "score": 0.9373900294303894,
      "strategy": "Use a mixed strategy where the row player randomly chooses to coordinate with the column player on t"
    },
    "root_1": {
      "depth": 1,
      "num_children": 1,
      "score": 0.9321799874305725,
      "strategy": "Adopt a mixed strategy where the row player chooses \"cooperate\" with a probability of 0.6 and \"defec"
    },
    "root_2": {
      "depth": 1,
      "num_children": 1,
      "score": 0.9399599432945251,
      "strategy": "Adopt a mixed strategy where the row player chooses \"cooperate\" with a probability of 0.6 and \"defec"
    },
    "root_2_0": {
      "depth": 2,
      "num_children": 1,
      "score": 1.1316099166870117,
      "strategy": "Adopt a dynamic adaptive strategy where the row player adjusts the cooperation probability based on "
    },
    "root_2_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 1.115470051765442,
      "strategy": "Implement a temperature-based stochastic strategy where the row player's cooperation probability is "
    },
    "root_2_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.600909948348999,
      "strategy": "Implement a phase-shifted oscillatory strategy where the row player alternates between cooperation a"
    },
    "root_0_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.7371399998664856,
      "strategy": "Adopt a time-dependent mixed strategy where the row player adjusts the probability of choosing the \""
    },
    "root_1_0": {
      "depth": 2,
      "num_children": 1,
      "score": 0.683180034160614,
      "strategy": "Implement a time-dependent mixed strategy where the row player adjusts cooperation probability based"
    },
    "root_0_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 0.7812900543212891,
      "strategy": "Implement a weather-dependent mixed strategy where the row player adjusts the probability of choosin"
    },
    "root_0_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.7249400019645691,
      "strategy": "Implement a time-of-day based mixed strategy where the row player adjusts their probability of choos"
    },
    "root_0_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 0.7341700196266174,
      "strategy": "Implement a weather-dependent mixed strategy where the row player adjusts their probability of choos"
    },
    "root_0_0_0_0_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.7057600021362305,
      "strategy": "Implement a time-of-day based mixed strategy where the row player adjusts their probability of choos"
    },
    "root_0_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 1,
      "score": 0.6752300262451172,
      "strategy": "Implement a weather-dependent mixed strategy where the row player adjusts their probability of choos"
    },
    "root_1_0_0": {
      "depth": 3,
      "num_children": 1,
      "score": 1.0614700317382812,
      "strategy": "Implement a temperature-dependent mixed strategy where the row player's cooperation probability is m"
    },
    "root_1_0_0_0": {
      "depth": 4,
      "num_children": 1,
      "score": 0.9387900233268738,
      "strategy": "Introduce a time-of-day dependent mixed strategy where the row player's cooperation probability is m"
    },
    "root_1_0_0_0_0": {
      "depth": 5,
      "num_children": 0,
      "score": 0.32686999440193176,
      "strategy": "Introduce a weather-dependent mixed strategy where the row player adjusts cooperation probability ba"
    },
    "root_0_0_0_0_0_0_0_0": {
      "depth": 8,
      "num_children": 1,
      "score": 0.9103599786758423,
      "strategy": "Implement a sentiment-based mixed strategy using real-time social media sentiment analysis from loca"
    },
    "root_0_0_0_0_0_0_0_0_0": {
      "depth": 9,
      "num_children": 1,
      "score": 1.0052900314331055,
      "strategy": "Implement a time-series forecasting model using LSTM networks to predict the likelihood of coordinat"
    },
    "root_0_0_0_0_0_0_0_0_0_0": {
      "depth": 10,
      "num_children": 1,
      "score": 1.0102698802947998,
      "strategy": "Implement a Bayesian reinforcement learning framework where the row player updates beliefs about the"
    },
    "root_0_0_0_0_0_0_0_0_0_0_0": {
      "depth": 11,
      "num_children": 1,
      "score": 1.2565299272537231,
      "strategy": "Implement a dynamic threshold-based strategy where the row player monitors the entropy of the column"
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0": {
      "depth": 12,
      "num_children": 1,
      "score": 0.6595900058746338,
      "strategy": "Implement a time-delayed feedback strategy where the row player observes the column player's last mo"
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "depth": 13,
      "num_children": 1,
      "score": 1.4368400573730469,
      "strategy": "Implement a phase-shifted mirror strategy where the row player anticipates the column player's move "
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "depth": 14,
      "num_children": 1,
      "score": 1.0808299779891968,
      "strategy": "Implement a machine learning-based adaptive response strategy using a recurrent neural network (RNN)"
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "depth": 15,
      "num_children": 1,
      "score": 1.009909987449646,
      "strategy": "Implement a reinforcement learning-based strategy using a Proximal Policy Optimization (PPO) agent t"
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "depth": 16,
      "num_children": 0,
      "score": 0.5407100319862366,
      "strategy": "Implement a Bayesian belief-updating strategy where the row player maintains a posterior distributio"
    },
    "root_2_0_0_0_0": {
      "depth": 5,
      "num_children": 1,
      "score": 1.4365400075912476,
      "strategy": "Implement a fractal-based adaptive strategy where the row player's cooperation decision is determine"
    },
    "root_2_0_0_0_0_0": {
      "depth": 6,
      "num_children": 1,
      "score": 0.9809099435806274,
      "strategy": "Implement a phase-shifted sine-wave adaptation strategy where the row player's cooperation decision "
    },
    "root_2_0_0_0_0_0_0": {
      "depth": 7,
      "num_children": 1,
      "score": 1.3040200471878052,
      "strategy": "Implement a time-series momentum-based cooperation threshold strategy where the row player's coopera"
    },
    "root_2_0_0_0_0_0_0_0": {
      "depth": 8,
      "num_children": 1,
      "score": 1.2816001176834106,
      "strategy": "Implement a reinforcement learning-based epsilon-greedy policy where the row player selects cooperat"
    },
    "root_2_0_0_0_0_0_0_0_0": {
      "depth": 9,
      "num_children": 0,
      "score": 0.8801000118255615,
      "strategy": "Implement a contextual bandit strategy where the row player's action (cooperate or defect) is determ"
    }
  },
  "nodes": {
    "root": {
      "node_id": "root",
      "parent_id": null,
      "depth": 0,
      "strategy": "Baseline (no model execution)",
      "score": 1.0226699113845825,
      "actions_count": 0,
      "children": [
        "root_0",
        "root_1",
        "root_2"
      ],
      "error": null
    },
    "root_0": {
      "node_id": "root_0",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Use a mixed strategy where the row player randomly chooses to coordinate with the column player on t",
      "score": 0.9373900294303894,
      "actions_count": 2,
      "children": [
        "root_0_0"
      ],
      "error": null
    },
    "root_1": {
      "node_id": "root_1",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Adopt a mixed strategy where the row player chooses \"cooperate\" with a probability of 0.6 and \"defec",
      "score": 0.9321799874305725,
      "actions_count": 2,
      "children": [
        "root_1_0"
      ],
      "error": null
    },
    "root_2": {
      "node_id": "root_2",
      "parent_id": "root",
      "depth": 1,
      "strategy": "Adopt a mixed strategy where the row player chooses \"cooperate\" with a probability of 0.6 and \"defec",
      "score": 0.9399599432945251,
      "actions_count": 2,
      "children": [
        "root_2_0"
      ],
      "error": null
    },
    "root_2_0": {
      "node_id": "root_2_0",
      "parent_id": "root_2",
      "depth": 2,
      "strategy": "Adopt a dynamic adaptive strategy where the row player adjusts the cooperation probability based on ",
      "score": 1.1316099166870117,
      "actions_count": 2,
      "children": [
        "root_2_0_0"
      ],
      "error": null
    },
    "root_2_0_0": {
      "node_id": "root_2_0_0",
      "parent_id": "root_2_0",
      "depth": 3,
      "strategy": "Implement a temperature-based stochastic strategy where the row player's cooperation probability is ",
      "score": 1.115470051765442,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0": {
      "node_id": "root_2_0_0_0",
      "parent_id": "root_2_0_0",
      "depth": 4,
      "strategy": "Implement a phase-shifted oscillatory strategy where the row player alternates between cooperation a",
      "score": 0.600909948348999,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0": {
      "node_id": "root_0_0",
      "parent_id": "root_0",
      "depth": 2,
      "strategy": "Adopt a time-dependent mixed strategy where the row player adjusts the probability of choosing the \"",
      "score": 0.7371399998664856,
      "actions_count": 2,
      "children": [
        "root_0_0_0"
      ],
      "error": null
    },
    "root_1_0": {
      "node_id": "root_1_0",
      "parent_id": "root_1",
      "depth": 2,
      "strategy": "Implement a time-dependent mixed strategy where the row player adjusts cooperation probability based",
      "score": 0.683180034160614,
      "actions_count": 2,
      "children": [
        "root_1_0_0"
      ],
      "error": null
    },
    "root_0_0_0": {
      "node_id": "root_0_0_0",
      "parent_id": "root_0_0",
      "depth": 3,
      "strategy": "Implement a weather-dependent mixed strategy where the row player adjusts the probability of choosin",
      "score": 0.7812900543212891,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0": {
      "node_id": "root_0_0_0_0",
      "parent_id": "root_0_0_0",
      "depth": 4,
      "strategy": "Implement a time-of-day based mixed strategy where the row player adjusts their probability of choos",
      "score": 0.7249400019645691,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0",
      "parent_id": "root_0_0_0_0",
      "depth": 5,
      "strategy": "Implement a weather-dependent mixed strategy where the row player adjusts their probability of choos",
      "score": 0.7341700196266174,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0",
      "depth": 6,
      "strategy": "Implement a time-of-day based mixed strategy where the row player adjusts their probability of choos",
      "score": 0.7057600021362305,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0",
      "depth": 7,
      "strategy": "Implement a weather-dependent mixed strategy where the row player adjusts their probability of choos",
      "score": 0.6752300262451172,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0": {
      "node_id": "root_1_0_0",
      "parent_id": "root_1_0",
      "depth": 3,
      "strategy": "Implement a temperature-dependent mixed strategy where the row player's cooperation probability is m",
      "score": 1.0614700317382812,
      "actions_count": 2,
      "children": [
        "root_1_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0": {
      "node_id": "root_1_0_0_0",
      "parent_id": "root_1_0_0",
      "depth": 4,
      "strategy": "Introduce a time-of-day dependent mixed strategy where the row player's cooperation probability is m",
      "score": 0.9387900233268738,
      "actions_count": 2,
      "children": [
        "root_1_0_0_0_0"
      ],
      "error": null
    },
    "root_1_0_0_0_0": {
      "node_id": "root_1_0_0_0_0",
      "parent_id": "root_1_0_0_0",
      "depth": 5,
      "strategy": "Introduce a weather-dependent mixed strategy where the row player adjusts cooperation probability ba",
      "score": 0.32686999440193176,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Implement a sentiment-based mixed strategy using real-time social media sentiment analysis from loca",
      "score": 0.9103599786758423,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0",
      "depth": 9,
      "strategy": "Implement a time-series forecasting model using LSTM networks to predict the likelihood of coordinat",
      "score": 1.0052900314331055,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0",
      "depth": 10,
      "strategy": "Implement a Bayesian reinforcement learning framework where the row player updates beliefs about the",
      "score": 1.0102698802947998,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_0",
      "depth": 11,
      "strategy": "Implement a dynamic threshold-based strategy where the row player monitors the entropy of the column",
      "score": 1.2565299272537231,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_0_0",
      "depth": 12,
      "strategy": "Implement a time-delayed feedback strategy where the row player observes the column player's last mo",
      "score": 0.6595900058746338,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_0_0_0",
      "depth": 13,
      "strategy": "Implement a phase-shifted mirror strategy where the row player anticipates the column player's move ",
      "score": 1.4368400573730469,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0",
      "depth": 14,
      "strategy": "Implement a machine learning-based adaptive response strategy using a recurrent neural network (RNN)",
      "score": 1.0808299779891968,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0",
      "depth": 15,
      "strategy": "Implement a reinforcement learning-based strategy using a Proximal Policy Optimization (PPO) agent t",
      "score": 1.009909987449646,
      "actions_count": 2,
      "children": [
        "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0": {
      "node_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0",
      "parent_id": "root_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0",
      "depth": 16,
      "strategy": "Implement a Bayesian belief-updating strategy where the row player maintains a posterior distributio",
      "score": 0.5407100319862366,
      "actions_count": 2,
      "children": [],
      "error": null
    },
    "root_2_0_0_0_0": {
      "node_id": "root_2_0_0_0_0",
      "parent_id": "root_2_0_0_0",
      "depth": 5,
      "strategy": "Implement a fractal-based adaptive strategy where the row player's cooperation decision is determine",
      "score": 1.4365400075912476,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0",
      "depth": 6,
      "strategy": "Implement a phase-shifted sine-wave adaptation strategy where the row player's cooperation decision ",
      "score": 0.9809099435806274,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0",
      "depth": 7,
      "strategy": "Implement a time-series momentum-based cooperation threshold strategy where the row player's coopera",
      "score": 1.3040200471878052,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0_0",
      "depth": 8,
      "strategy": "Implement a reinforcement learning-based epsilon-greedy policy where the row player selects cooperat",
      "score": 1.2816001176834106,
      "actions_count": 2,
      "children": [
        "root_2_0_0_0_0_0_0_0_0"
      ],
      "error": null
    },
    "root_2_0_0_0_0_0_0_0_0": {
      "node_id": "root_2_0_0_0_0_0_0_0_0",
      "parent_id": "root_2_0_0_0_0_0_0_0",
      "depth": 9,
      "strategy": "Implement a contextual bandit strategy where the row player's action (cooperate or defect) is determ",
      "score": 0.8801000118255615,
      "actions_count": 2,
      "children": [],
      "error": null
    }
  }
}