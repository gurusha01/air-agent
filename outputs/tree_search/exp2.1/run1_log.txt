Setting up logger for name='MLGym'
Setting up logger for name='env_utils'
============================================================
Experiment 2: Tree Search with VS (tail-distribution)
============================================================
Model: Qwen/Qwen3-4B-Instruct-2507
Branching: 3, Depth: 2
Max actions/node: 15
Temperature: 0.9
Verbalized sampling: True (mode: tail)

Creating MLGym container...
Setting up logger for name='MLGymEnv'
INFO     Found image aigym/mlgym-agent:latest with tags:                        
         ['aigym/mlgym-agent:latest'], created: 2024-11-04T13:33:17.818245514Z  
         for linux amd64.                                                       
DEBUG    Starting container with command: docker run -i --rm --network host     
         --gpus '"device=7"' --name aigym-mlgym-agent-latest-d_7-cbdcd812d3     
         aigym/mlgym-agent:latest /bin/bash -l                                  
Setting up logger for name='MLGymTask'
DEBUG    Copying data/titanic/data to container at /home/agent/workspace/data   
         with command: docker cp data/titanic/data                              
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950:/home/
         agent/workspace/data                                                   
DEBUG    Setting agent as owner of copied files at /home/agent/workspace/data   
         with command: docker exec -u root                                      
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950 chown 
         -R agent:mlgym /home/agent/workspace/data                              
DEBUG    Copying data/titanic/evaluate.py to container at /home/agent/workspace/
         with command: docker cp data/titanic/evaluate.py                       
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950:/home/
         agent/workspace/                                                       
DEBUG    Setting agent as owner of copied files at /home/agent/workspace/ with  
         command: docker exec -u root                                           
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950 chown 
         -R agent:mlgym /home/agent/workspace/                                  
DEBUG    Copying /tmp/tmpknsrjsl4 to container at                               
         /home/agent/commands/defaults.sh with command: docker cp               
         /tmp/tmpknsrjsl4                                                       
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950:/home/
         agent/commands/defaults.sh                                             
DEBUG    Setting agent as owner of copied files at                              
         /home/agent/commands/defaults.sh with command: docker exec -u root     
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950 chown 
         -R agent:mlgym /home/agent/commands/defaults.sh                        
DEBUG    Copying /tmp/tmp_wzyz313 to container at /home/agent/commands/search.sh
         with command: docker cp /tmp/tmp_wzyz313                               
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950:/home/
         agent/commands/search.sh                                               
DEBUG    Setting agent as owner of copied files at                              
         /home/agent/commands/search.sh with command: docker exec -u root       
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950 chown 
         -R agent:mlgym /home/agent/commands/search.sh                          
DEBUG    Copying /tmp/tmpj5up2y0o to container at                               
         /home/agent/commands/edit_linting.sh with command: docker cp           
         /tmp/tmpj5up2y0o                                                       
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950:/home/
         agent/commands/edit_linting.sh                                         
DEBUG    Setting agent as owner of copied files at                              
         /home/agent/commands/edit_linting.sh with command: docker exec -u root 
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950 chown 
         -R agent:mlgym /home/agent/commands/edit_linting.sh                    
DEBUG    Copying /tmp/tmpv1tusz68 to container at                               
         /home/agent/commands/validate.sh with command: docker cp               
         /tmp/tmpv1tusz68                                                       
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950:/home/
         agent/commands/validate.sh                                             
DEBUG    Setting agent as owner of copied files at                              
         /home/agent/commands/validate.sh with command: docker exec -u root     
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950 chown 
         -R agent:mlgym /home/agent/commands/validate.sh                        
DEBUG    Copying /tmp/tmpbx3l0cur to container at /home/agent/commands/submit.sh
         with command: docker cp /tmp/tmpbx3l0cur                               
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950:/home/
         agent/commands/submit.sh                                               
DEBUG    Setting agent as owner of copied files at                              
         /home/agent/commands/submit.sh with command: docker exec -u root       
         53a1df56d4059ea975cb280f290186e58906711539c13b850cf3cde1ba35e950 chown 
         -R agent:mlgym /home/agent/commands/submit.sh                          
Container created. Baseline: 0.7655

============================================================
TREE SEARCH - Root Node
============================================================
    [root] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root] step 1: validate
    [root] validate score=[]
    [root] step 2: python train_and_predict.py
    [root] python ERROR: /site-packages/pandas/core/generic.py", line 2153, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Va
    [root] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root] step 4: validate
    [root] validate score=[]
    [root] step 5: python train_and_predict.py
    [root] python ERROR: iconda3/envs/mlgym_generic/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 6252, in _raise_if_missing
    raise KeyError(f"{not_found}
    [root] step 6: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root] step 7: validate
    [root] validate score=[]
    [root] step 8: python train_and_predict.py
    [root] step 9: validate
    [root] validate score=[{'accuracy': 0.8229665071770335}]
  [root] validate → 0.8230

============================================================
TREE SEARCH - Depth 1 (1 nodes to expand)
============================================================

  Generating strategies for root (score=0.8230) [tail-sampling]...

  --- Branch root_0 (p=0.12) ---
  Strategy: Apply a gradient-boosted tree model (e.g., LightGBM or XGBoost) with optimized hyperparameters via B
    [root_0] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0] step 1: validate
    [root_0] validate score=[]
    [root_0] step 2: python train_and_predict.py
    [root_0] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 4, in <module>
    from xgboost import XGBClassifier
Modu
    [root_0] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0] step 4: validate
    [root_0] validate score=[]
    [root_0] step 5: python train_and_predict.py
    [root_0] python ERROR: rain, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
                                     ^^^^^^^^^^^^^^^^
    [root_0] step 6: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0] step 7: validate
    [root_0] validate score=[]
    [root_0] step 8: python train_and_predict.py
    [root_0] python ERROR: org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/mod
    [root_0] step 9: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0] step 10: validate
    [root_0] validate score=[]
    [root_0] step 11: python train_and_predict.py
    [root_0] step 12: validate
    [root_0] validate score=[{'accuracy': 0.8205741626794258}]
  [root_0] validate → 0.8206

  --- Branch root_1 (p=0.15) ---
  Strategy: Perform advanced feature engineering by creating interaction features such as "age_group * fare_cate
    [root_1] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1] step 1: python train_and_predict.py
    [root_1] step 2: validate
    [root_1] validate score=[{'accuracy': 0.84688995215311}]
  [root_1] validate → 0.8469

  --- Branch root_2 (p=0.11) ---
  Strategy: Implement a neural network with an input layer for continuous features (age, fare), an embedding lay
    [root_2] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2] step 1: validate
    [root_2] validate score=[]
    [root_2] step 2: python train_and_predict.py
    [root_2] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 6, in <module>
    import tensorflow as tf
ModuleNotFound
    [root_2] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2] step 4: validate
    [root_2] validate score=[]
    [root_2] step 5: python train_and_predict.py
    [root_2] python ERROR: py", line 45, in <module>
    model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)
            ^^^^^^^^^^^^^^^^^^^^^^
NameE
    [root_2] step 6: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2] step 7: validate
    [root_2] validate score=[]
    [root_2] step 8: python train_and_predict.py
    [root_2] step 9: validate
    [root_2] validate score=[{'accuracy': 0.8397129186602871}]
  [root_2] validate → 0.8397

============================================================
TREE SEARCH - Depth 2 (3 nodes to expand)
============================================================

  Generating strategies for root_0 (score=0.8206) [tail-sampling]...

  --- Branch root_0_0 (p=0.08) ---
  Strategy: Introduce a neural network with an attention mechanism to dynamically weight features like passenger
    [root_0_0] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_0] step 1: validate
    [root_0_0] validate score=[]
    [root_0_0] step 2: python train_and_predict.py
    [root_0_0] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 5, in <module>
    import tensorflow as tf
ModuleNotFound
    [root_0_0] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_0] step 4: validate
    [root_0_0] validate score=[]
    [root_0_0] step 5: python train_and_predict.py
    [root_0_0] step 6: validate
    [root_0_0] validate score=[{'accuracy': 0.8851674641148325}]
  [root_0_0] validate → 0.8852

  --- Branch root_0_1 (p=0.12) ---
  Strategy: Apply a random forest with subsampling with replacement (bootstrap aggregation) and introduce a synt
    [root_0_1] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_1] step 1: validate
    [root_0_1] validate score=[]
    [root_0_1] step 2: python train_and_predict.py
    [root_0_1] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 5, in <module>
    from imblearn.over_sampling import SMO
    [root_0_1] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_1] step 4: validate
    [root_0_1] validate score=[]
    [root_0_1] step 5: python train_and_predict.py
    [root_0_1] step 6: validate
    [root_0_1] validate score=[{'accuracy': 0.8660287081339713}]
  [root_0_1] validate → 0.8660

  --- Branch root_0_2 (p=0.09) ---
  Strategy: Perform deep feature learning using autoencoders to extract latent representations from raw passenge
    [root_0_2] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_2] step 1: validate
    [root_0_2] validate score=[]
    [root_0_2] step 2: python train_and_predict.py
    [root_0_2] python ERROR: on3.11/site-packages/pandas/core/generic.py", line 1577, in __nonzero__
    raise ValueError(
ValueError: The truth value of a Series is ambiguous. Us
    [root_0_2] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_2] step 4: validate
    [root_0_2] validate score=[]
    [root_0_2] step 5: python train_and_predict.py
    [root_0_2] python ERROR: 1/site-packages/pandas/core/generic.py", line 2153, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
V
    [root_0_2] step 6: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_2] step 7: validate
    [root_0_2] validate score=[]
    [root_0_2] step 8: python train_and_predict.py
    [root_0_2] python ERROR: e-packages/pandas/core/generic.py", line 2153, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueE
    [root_0_2] step 9: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_2] step 10: validate
    [root_0_2] validate score=[]
    [root_0_2] step 11: python train_and_predict.py
    [root_0_2] python ERROR: thon3.11/site-packages/pandas/core/indexes/base.py", line 6252, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Tick
    [root_0_2] step 12: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_0_2] step 13: validate
    [root_0_2] validate score=[]
    [root_0_2] step 14: python train_and_predict.py
    [root_0_2] python ERROR: thon3.11/site-packages/pandas/core/indexes/base.py", line 6252, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Tick
  [root_0_2] Max actions reached, forcing validate

  Generating strategies for root_1 (score=0.8469) [tail-sampling]...

  --- Branch root_1_0 (p=0.12) ---
  Strategy: Switch to a gradient-boosted tree model (e.g., XGBoost or LightGBM) with early stopping and hyperpar
    [root_1_0] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_0] step 1: python train_and_predict.py
    [root_1_0] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 3, in <module>
    from xgboost import XGBClassifier
Modu
    [root_1_0] step 2: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_0] step 3: python train_and_predict.py
    [root_1_0] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 3, in <module>
    from lightgbm import LGBMClassifier
Mo
    [root_1_0] step 4: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_0] step 5: python train_and_predict.py
    [root_1_0] python ERROR: org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/mod
    [root_1_0] step 6: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_0] step 7: python train_and_predict.py
    [root_1_0] step 8: validate
    [root_1_0] validate score=[{'accuracy': 0.8708133971291866}]
  [root_1_0] validate → 0.8708

  --- Branch root_1_1 (p=0.15) ---
  Strategy: Apply a neural network with a shallow architecture (2–3 hidden layers, 64–128 neurons) to model comp
    [root_1_1] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_1] step 1: python train_and_predict.py
    [root_1_1] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 6, in <module>
    import tensorflow as tf
ModuleNotFound
    [root_1_1] step 2: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_1] step 3: python train_and_predict.py
    [root_1_1] python ERROR: k (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 65, in <module>
    le_sex = LabelEncoder()
             ^^^^^^^^
    [root_1_1] step 4: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_1] step 5: python train_and_predict.py
    [root_1_1] step 6: validate
    [root_1_1] validate score=[{'accuracy': 0.84688995215311}]
  [root_1_1] validate → 0.8469

  --- Branch root_1_2 (p=0.10) ---
  Strategy: Replace all engineered categorical features with embeddings (e.g., using one-hot encoding with spars
    [root_1_2] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_2] step 1: python train_and_predict.py
    [root_1_2] python ERROR:  745, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Val
    [root_1_2] step 2: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_2] step 3: python train_and_predict.py
    [root_1_2] python ERROR: org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/mod
    [root_1_2] step 4: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_1_2] step 5: python train_and_predict.py
    [root_1_2] step 6: validate
    [root_1_2] validate score=[{'accuracy': 0.6435406698564593}]
  [root_1_2] validate → 0.6435

  Generating strategies for root_2 (score=0.8397) [tail-sampling]...

  --- Branch root_2_0 (p=0.12) ---
  Strategy: Replace the neural network with a gradient boosting ensemble (e.g., XGBoost or LightGBM) using all f
    [root_2_0] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_0] step 1: validate
    [root_2_0] validate score=[]
    [root_2_0] step 2: python train_and_predict.py
    [root_2_0] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 5, in <module>
    from xgboost import XGBClassifier
Modu
    [root_2_0] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_0] step 4: validate
    [root_2_0] validate score=[]
    [root_2_0] step 5: python train_and_predict.py
    [root_2_0] python ERROR: ckages/pandas/core/generic.py", line 2153, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError
    [root_2_0] step 6: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_0] step 7: validate
    [root_2_0] validate score=[]
    [root_2_0] step 8: python train_and_predict.py
    [root_2_0] python ERROR: ckages/pandas/core/generic.py", line 2153, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError
    [root_2_0] step 9: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_0] step 10: validate
    [root_2_0] validate score=[]
    [root_2_0] step 11: python train_and_predict.py
    [root_2_0] python ERROR: ckages/pandas/core/generic.py", line 2153, in __array__
    arr = np.asarray(values, dtype=dtype)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError
    [root_2_0] step 12: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_0] step 13: validate
    [root_2_0] validate score=[]
    [root_2_0] step 14: python train_and_predict.py
    [root_2_0] python ERROR: org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/mod
  [root_2_0] Max actions reached, forcing validate

  --- Branch root_2_1 (p=0.15) ---
  Strategy: Introduce a hybrid model combining a random forest with autoencoders for anomaly detection in the da
    [root_2_1] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_1] step 1: validate
    [root_2_1] validate score=[]
    [root_2_1] step 2: python train_and_predict.py
    [root_2_1] python ERROR: _scaled - pca.transform(X_scaled)) ** 2, axis=1)
                                   ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~
ValueError: operands could not 
    [root_2_1] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_1] step 4: validate
    [root_2_1] validate score=[]
    [root_2_1] step 5: python train_and_predict.py
    [root_2_1] step 6: validate
    [root_2_1] validate score=[{'accuracy': 0.34688995215311}]
  [root_2_1] validate → 0.3469

  --- Branch root_2_2 (p=0.11) ---
  Strategy: Apply a deep autoencoder with a fully connected output layer to reconstruct the input features and u
    [root_2_2] step 0: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_2] step 1: validate
    [root_2_2] validate score=[]
    [root_2_2] step 2: python train_and_predict.py
    [root_2_2] python ERROR: Traceback (most recent call last):
  File "/home/agent/workspace/train_and_predict.py", line 6, in <module>
    import tensorflow as tf
ModuleNotFound
    [root_2_2] step 3: cat << 'ENDOFFILE' > train_and_predict.py
import pandas as pd
import numpy as np
    [root_2_2] step 4: validate
    [root_2_2] validate score=[]
    [root_2_2] step 5: python train_and_predict.py
    [root_2_2] step 6: validate
    [root_2_2] validate score=[{'accuracy': 0.8397129186602871}]
  [root_2_2] validate → 0.8397

======================================================================
TREE SEARCH RESULTS
======================================================================
Baseline: 0.7655 | Best: 0.8852 (node: root_0_0) | Improvement: +0.1196
Nodes explored: 13
======================================================================

└── root [0.8230] Initial solution
    ├── root_0 [0.8206] Apply a gradient-boosted tree model (e.g., LightGB
    │   ├── root_0_0 [0.8852] Introduce a neural network with an attention mecha *** BEST ***
    │   ├── root_0_1 [0.8660] Apply a random forest with subsampling with replac
    │   └── root_0_2 [FAIL] Perform deep feature learning using autoencoders t
    ├── root_1 [0.8469] Perform advanced feature engineering by creating i
    │   ├── root_1_0 [0.8708] Switch to a gradient-boosted tree model (e.g., XGB
    │   ├── root_1_1 [0.8469] Apply a neural network with a shallow architecture
    │   └── root_1_2 [0.6435] Replace all engineered categorical features with e
    └── root_2 [0.8397] Implement a neural network with an input layer for
        ├── root_2_0 [FAIL] Replace the neural network with a gradient boostin
        ├── root_2_1 [0.3469] Introduce a hybrid model combining a random forest
        └── root_2_2 [0.8397] Apply a deep autoencoder with a fully connected ou

Best path: root -> root_0 -> root_0_0
  root: [0.8230] Initial solution
  root_0: [0.8206] Apply a gradient-boosted tree model (e.g., LightGBM or XGBoost) with optimized h
  root_0_0: [0.8852] Introduce a neural network with an attention mechanism to dynamically weight fea

Results saved to outputs/tree_search/exp2.1/run1/result.json
